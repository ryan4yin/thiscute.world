<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1/" version="2.0"><channel><title>Kubernetes - 标签 - Ryan4Yin's Space</title><link>https://ryan4yin.space/tags/kubernetes/</link><description>Kubernetes - 标签 - Ryan4Yin's Space</description><generator>Hugo -- gohugo.io</generator><language>zh-CN</language><managingEditor>xiaoyin_c@qq.com (ryan4yin)</managingEditor><webMaster>xiaoyin_c@qq.com (ryan4yin)</webMaster><lastBuildDate>Tue, 25 Jan 2022 00:13:00 +0800</lastBuildDate><atom:link href="https://ryan4yin.space/tags/kubernetes/" rel="self" type="application/rss+xml"/><item><title>Kubernetes 微服务最佳实践</title><link>https://ryan4yin.space/posts/kubernetes-best-practices/</link><pubDate>Tue, 25 Jan 2022 00:13:00 +0800</pubDate><author>xiaoyin_c@qq.com</author><dc:creator>ryan4yin</dc:creator><guid>https://ryan4yin.space/posts/kubernetes-best-practices/</guid><description><![CDATA[<blockquote>
<p>个人笔记，不保证正确</p>
</blockquote>
<p>本文主要介绍下我个人在使用 Kubernetes 的过程中，总结出的一套「Kubernetes 配置」，是我个人的「最佳实践」。
其中大部分内容都经历过线上环境的考验，但是也有少部分还只在我脑子里模拟过，请谨慎参考。</p>
<p>阅读前的几个注意事项：</p>
<ul>
<li>这份文档比较长，囊括了很多内容，建议当成参考手册使用，先简单读一读，有需要再细读相关内容。</li>
<li>这份文档需要一定的 Kubernetes 基础才能理解，而且如果没有过实践经验的话，看上去可能会比较枯燥。
<ul>
<li>而有过实践经验的大佬，可能会跟我有不同的见解，欢迎各路大佬评论~</li>
</ul>
</li>
</ul>
<p>我会视情况不定期更新这份文档。</p>
<h2 id="零示例">零、示例</h2>
<p>首先，这里给出一些本文遵守的前提，这些前提只是契合我遇到的场景，可灵活变通：</p>
<ul>
<li>这里只讨论无状态服务，有状态服务不在讨论范围内</li>
<li>我们不使用 Deployment 的滚动更新能力，而是为每个服务的每个版本，都创建不同的 Deployment + HPA + PodDisruptionBudget，这是为了方便做金丝雀/灰度发布</li>
<li>我们的服务可能会使用 IngressController / Service Mesh 来进行服务的负载均衡、流量切分</li>
</ul>
<p>下面先给出一个 Deployment + HPA + PodDisruptionBudget 的 demo，后面再拆开详细说下：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">  1
</span><span class="lnt">  2
</span><span class="lnt">  3
</span><span class="lnt">  4
</span><span class="lnt">  5
</span><span class="lnt">  6
</span><span class="lnt">  7
</span><span class="lnt">  8
</span><span class="lnt">  9
</span><span class="lnt"> 10
</span><span class="lnt"> 11
</span><span class="lnt"> 12
</span><span class="lnt"> 13
</span><span class="lnt"> 14
</span><span class="lnt"> 15
</span><span class="lnt"> 16
</span><span class="lnt"> 17
</span><span class="lnt"> 18
</span><span class="lnt"> 19
</span><span class="lnt"> 20
</span><span class="lnt"> 21
</span><span class="lnt"> 22
</span><span class="lnt"> 23
</span><span class="lnt"> 24
</span><span class="lnt"> 25
</span><span class="lnt"> 26
</span><span class="lnt"> 27
</span><span class="lnt"> 28
</span><span class="lnt"> 29
</span><span class="lnt"> 30
</span><span class="lnt"> 31
</span><span class="lnt"> 32
</span><span class="lnt"> 33
</span><span class="lnt"> 34
</span><span class="lnt"> 35
</span><span class="lnt"> 36
</span><span class="lnt"> 37
</span><span class="lnt"> 38
</span><span class="lnt"> 39
</span><span class="lnt"> 40
</span><span class="lnt"> 41
</span><span class="lnt"> 42
</span><span class="lnt"> 43
</span><span class="lnt"> 44
</span><span class="lnt"> 45
</span><span class="lnt"> 46
</span><span class="lnt"> 47
</span><span class="lnt"> 48
</span><span class="lnt"> 49
</span><span class="lnt"> 50
</span><span class="lnt"> 51
</span><span class="lnt"> 52
</span><span class="lnt"> 53
</span><span class="lnt"> 54
</span><span class="lnt"> 55
</span><span class="lnt"> 56
</span><span class="lnt"> 57
</span><span class="lnt"> 58
</span><span class="lnt"> 59
</span><span class="lnt"> 60
</span><span class="lnt"> 61
</span><span class="lnt"> 62
</span><span class="lnt"> 63
</span><span class="lnt"> 64
</span><span class="lnt"> 65
</span><span class="lnt"> 66
</span><span class="lnt"> 67
</span><span class="lnt"> 68
</span><span class="lnt"> 69
</span><span class="lnt"> 70
</span><span class="lnt"> 71
</span><span class="lnt"> 72
</span><span class="lnt"> 73
</span><span class="lnt"> 74
</span><span class="lnt"> 75
</span><span class="lnt"> 76
</span><span class="lnt"> 77
</span><span class="lnt"> 78
</span><span class="lnt"> 79
</span><span class="lnt"> 80
</span><span class="lnt"> 81
</span><span class="lnt"> 82
</span><span class="lnt"> 83
</span><span class="lnt"> 84
</span><span class="lnt"> 85
</span><span class="lnt"> 86
</span><span class="lnt"> 87
</span><span class="lnt"> 88
</span><span class="lnt"> 89
</span><span class="lnt"> 90
</span><span class="lnt"> 91
</span><span class="lnt"> 92
</span><span class="lnt"> 93
</span><span class="lnt"> 94
</span><span class="lnt"> 95
</span><span class="lnt"> 96
</span><span class="lnt"> 97
</span><span class="lnt"> 98
</span><span class="lnt"> 99
</span><span class="lnt">100
</span><span class="lnt">101
</span><span class="lnt">102
</span><span class="lnt">103
</span><span class="lnt">104
</span><span class="lnt">105
</span><span class="lnt">106
</span><span class="lnt">107
</span><span class="lnt">108
</span><span class="lnt">109
</span><span class="lnt">110
</span><span class="lnt">111
</span><span class="lnt">112
</span><span class="lnt">113
</span><span class="lnt">114
</span><span class="lnt">115
</span><span class="lnt">116
</span><span class="lnt">117
</span><span class="lnt">118
</span><span class="lnt">119
</span><span class="lnt">120
</span><span class="lnt">121
</span><span class="lnt">122
</span><span class="lnt">123
</span><span class="lnt">124
</span><span class="lnt">125
</span><span class="lnt">126
</span><span class="lnt">127
</span><span class="lnt">128
</span><span class="lnt">129
</span><span class="lnt">130
</span><span class="lnt">131
</span><span class="lnt">132
</span><span class="lnt">133
</span><span class="lnt">134
</span><span class="lnt">135
</span><span class="lnt">136
</span><span class="lnt">137
</span><span class="lnt">138
</span><span class="lnt">139
</span><span class="lnt">140
</span><span class="lnt">141
</span><span class="lnt">142
</span><span class="lnt">143
</span><span class="lnt">144
</span><span class="lnt">145
</span><span class="lnt">146
</span><span class="lnt">147
</span><span class="lnt">148
</span><span class="lnt">149
</span><span class="lnt">150
</span><span class="lnt">151
</span><span class="lnt">152
</span><span class="lnt">153
</span><span class="lnt">154
</span><span class="lnt">155
</span><span class="lnt">156
</span><span class="lnt">157
</span><span class="lnt">158
</span><span class="lnt">159
</span><span class="lnt">160
</span><span class="lnt">161
</span><span class="lnt">162
</span><span class="lnt">163
</span><span class="lnt">164
</span><span class="lnt">165
</span><span class="lnt">166
</span><span class="lnt">167
</span><span class="lnt">168
</span><span class="lnt">169
</span><span class="lnt">170
</span><span class="lnt">171
</span><span class="lnt">172
</span><span class="lnt">173
</span><span class="lnt">174
</span><span class="lnt">175
</span><span class="lnt">176
</span><span class="lnt">177
</span><span class="lnt">178
</span><span class="lnt">179
</span><span class="lnt">180
</span><span class="lnt">181
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-yaml" data-lang="yaml"><span class="nt">apiVersion</span><span class="p">:</span><span class="w"> </span><span class="l">apps/v1</span><span class="w">
</span><span class="w"></span><span class="nt">kind</span><span class="p">:</span><span class="w"> </span><span class="l">Deployment</span><span class="w">
</span><span class="w"></span><span class="nt">metadata</span><span class="p">:</span><span class="w">
</span><span class="w">  </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">my-app-v3</span><span class="w">
</span><span class="w">  </span><span class="nt">namespace</span><span class="p">:</span><span class="w"> </span><span class="l">prod</span><span class="w">
</span><span class="w">  </span><span class="nt">labels</span><span class="p">:</span><span class="w">
</span><span class="w">    </span><span class="nt">app</span><span class="p">:</span><span class="w"> </span><span class="l">my-app</span><span class="w">
</span><span class="w"></span><span class="nt">spec</span><span class="p">:</span><span class="w">
</span><span class="w">  </span><span class="nt">replicas</span><span class="p">:</span><span class="w"> </span><span class="m">3</span><span class="w">
</span><span class="w">  </span><span class="nt">strategy</span><span class="p">:</span><span class="w">
</span><span class="w">    </span><span class="nt">type</span><span class="p">:</span><span class="w"> </span><span class="l">RollingUpdate</span><span class="w">
</span><span class="w">    </span><span class="c"># 因为服务的每个版本都使用各自的 Deployment，服务更新时其实是用不上这里的滚动更新策略的</span><span class="w">
</span><span class="w">    </span><span class="c"># 这个配置应该只在 SRE 手动修改 Deployment 配置时才会生效（通常不应该发生这种事）</span><span class="w">
</span><span class="w">    </span><span class="nt">rollingUpdate</span><span class="p">:</span><span class="w">
</span><span class="w">      </span><span class="nt">maxSurge</span><span class="p">:</span><span class="w"> </span><span class="m">10</span><span class="l">% </span><span class="w"> </span><span class="c"># 滚动更新时，每次最多更新 10% 的 Pods</span><span class="w">
</span><span class="w">      </span><span class="nt">maxUnavailable</span><span class="p">:</span><span class="w"> </span><span class="m">0</span><span class="w">  </span><span class="c"># 滚动更新时，不允许出现不可用的 Pods，也就是说始终要维持 3 个可用副本</span><span class="w">
</span><span class="w">  </span><span class="nt">selector</span><span class="p">:</span><span class="w">
</span><span class="w">    </span><span class="nt">matchLabels</span><span class="p">:</span><span class="w">
</span><span class="w">      </span><span class="nt">app</span><span class="p">:</span><span class="w"> </span><span class="l">my-app</span><span class="w">
</span><span class="w">      </span><span class="nt">version</span><span class="p">:</span><span class="w"> </span><span class="l">v3</span><span class="w">
</span><span class="w">  </span><span class="nt">template</span><span class="p">:</span><span class="w">
</span><span class="w">    </span><span class="nt">metadata</span><span class="p">:</span><span class="w">
</span><span class="w">      </span><span class="nt">labels</span><span class="p">:</span><span class="w">
</span><span class="w">        </span><span class="nt">app</span><span class="p">:</span><span class="w"> </span><span class="l">my-app</span><span class="w">
</span><span class="w">        </span><span class="nt">version</span><span class="p">:</span><span class="w"> </span><span class="l">v3</span><span class="w">
</span><span class="w">    </span><span class="nt">spec</span><span class="p">:</span><span class="w">
</span><span class="w">      </span><span class="nt">affinity</span><span class="p">:</span><span class="w">
</span><span class="w">        </span><span class="nt">podAffinity</span><span class="p">:</span><span class="w">
</span><span class="w">          </span><span class="nt">preferredDuringSchedulingIgnoredDuringExecution</span><span class="p">:</span><span class="w"> </span><span class="c"># 非强制性条件</span><span class="w">
</span><span class="w">          </span>- <span class="nt">weight</span><span class="p">:</span><span class="w"> </span><span class="m">100</span><span class="w">  </span><span class="c"># weight 用于为节点评分，会优先选择评分最高的节点（只有一条规则的情况下，这个值没啥意义）</span><span class="w">
</span><span class="w">            </span><span class="nt">podAffinityTerm</span><span class="p">:</span><span class="w">
</span><span class="w">              </span><span class="nt">labelSelector</span><span class="p">:</span><span class="w">
</span><span class="w">                </span><span class="nt">matchExpressions</span><span class="p">:</span><span class="w">
</span><span class="w">                </span>- <span class="nt">key</span><span class="p">:</span><span class="w"> </span><span class="l">app</span><span class="w">
</span><span class="w">                  </span><span class="nt">operator</span><span class="p">:</span><span class="w"> </span><span class="l">In</span><span class="w">
</span><span class="w">                  </span><span class="nt">values</span><span class="p">:</span><span class="w">
</span><span class="w">                  </span>- <span class="l">my-app</span><span class="w">
</span><span class="w">                </span>- <span class="nt">key</span><span class="p">:</span><span class="w"> </span><span class="l">version</span><span class="w">
</span><span class="w">                  </span><span class="nt">operator</span><span class="p">:</span><span class="w"> </span><span class="l">In</span><span class="w">
</span><span class="w">                  </span><span class="nt">values</span><span class="p">:</span><span class="w">
</span><span class="w">                  </span>- <span class="l">v3</span><span class="w">
</span><span class="w">              </span><span class="c"># pod 尽量使用同一种节点类型，也就是尽量保证节点的性能一致</span><span class="w">
</span><span class="w">              </span><span class="nt">topologyKey</span><span class="p">:</span><span class="w"> </span><span class="l">node.kubernetes.io/instance-type</span><span class="w">
</span><span class="w">        </span><span class="nt">podAntiAffinity</span><span class="p">:</span><span class="w">
</span><span class="w">          </span><span class="nt">preferredDuringSchedulingIgnoredDuringExecution</span><span class="p">:</span><span class="w"> </span><span class="c"># 非强制性条件</span><span class="w">
</span><span class="w">          </span>- <span class="nt">weight</span><span class="p">:</span><span class="w"> </span><span class="m">100</span><span class="w">  </span><span class="c"># weight 用于为节点评分，会优先选择评分最高的节点（只有一条规则的情况下，这个值没啥意义）</span><span class="w">
</span><span class="w">            </span><span class="nt">podAffinityTerm</span><span class="p">:</span><span class="w">
</span><span class="w">              </span><span class="nt">labelSelector</span><span class="p">:</span><span class="w">
</span><span class="w">                </span><span class="nt">matchExpressions</span><span class="p">:</span><span class="w">
</span><span class="w">                </span>- <span class="nt">key</span><span class="p">:</span><span class="w"> </span><span class="l">app</span><span class="w">
</span><span class="w">                  </span><span class="nt">operator</span><span class="p">:</span><span class="w"> </span><span class="l">In</span><span class="w">
</span><span class="w">                  </span><span class="nt">values</span><span class="p">:</span><span class="w">
</span><span class="w">                  </span>- <span class="l">my-app</span><span class="w">
</span><span class="w">                </span>- <span class="nt">key</span><span class="p">:</span><span class="w"> </span><span class="l">version</span><span class="w">
</span><span class="w">                  </span><span class="nt">operator</span><span class="p">:</span><span class="w"> </span><span class="l">In</span><span class="w">
</span><span class="w">                  </span><span class="nt">values</span><span class="p">:</span><span class="w">
</span><span class="w">                  </span>- <span class="l">v3</span><span class="w">
</span><span class="w">              </span><span class="c"># 将 pod 尽量打散在多个可用区</span><span class="w">
</span><span class="w">              </span><span class="nt">topologyKey</span><span class="p">:</span><span class="w"> </span><span class="l">topology.kubernetes.io/zone</span><span class="w">
</span><span class="w">          </span><span class="nt">requiredDuringSchedulingIgnoredDuringExecution</span><span class="p">:</span><span class="w">  </span><span class="c"># 强制性要求（这个建议按需添加）</span><span class="w">
</span><span class="w">          </span><span class="c"># 注意这个没有 weights，必须满足列表中的所有条件</span><span class="w">
</span><span class="w">          </span>- <span class="nt">labelSelector</span><span class="p">:</span><span class="w">
</span><span class="w">              </span><span class="nt">matchExpressions</span><span class="p">:</span><span class="w">
</span><span class="w">              </span>- <span class="nt">key</span><span class="p">:</span><span class="w"> </span><span class="l">app</span><span class="w">
</span><span class="w">                </span><span class="nt">operator</span><span class="p">:</span><span class="w"> </span><span class="l">In</span><span class="w">
</span><span class="w">                </span><span class="nt">values</span><span class="p">:</span><span class="w">
</span><span class="w">                </span>- <span class="l">my-app</span><span class="w">
</span><span class="w">              </span>- <span class="nt">key</span><span class="p">:</span><span class="w"> </span><span class="l">version</span><span class="w">
</span><span class="w">                </span><span class="nt">operator</span><span class="p">:</span><span class="w"> </span><span class="l">In</span><span class="w">
</span><span class="w">                </span><span class="nt">values</span><span class="p">:</span><span class="w">
</span><span class="w">                </span>- <span class="l">v3</span><span class="w">
</span><span class="w">            </span><span class="c"># Pod 必须运行在不同的节点上</span><span class="w">
</span><span class="w">            </span><span class="nt">topologyKey</span><span class="p">:</span><span class="w"> </span><span class="l">kubernetes.io/hostname</span><span class="w">
</span><span class="w">      </span><span class="nt">securityContext</span><span class="p">:</span><span class="w">
</span><span class="w">        </span><span class="c"># runAsUser: 1000  # 设定用户</span><span class="w">
</span><span class="w">        </span><span class="c"># runAsGroup: 1000  # 设定用户组</span><span class="w">
</span><span class="w">        </span><span class="nt">runAsNonRoot</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span><span class="w">  </span><span class="c"># Pod 必须以非 root 用户运行</span><span class="w">
</span><span class="w">        </span><span class="nt">seccompProfile</span><span class="p">:</span><span class="w">  </span><span class="c"># security compute mode</span><span class="w">
</span><span class="w">          </span><span class="nt">type</span><span class="p">:</span><span class="w"> </span><span class="l">RuntimeDefault</span><span class="w">
</span><span class="w">      </span><span class="nt">nodeSelector</span><span class="p">:</span><span class="w">
</span><span class="w">        </span><span class="nt">eks.amazonaws.com/nodegroup</span><span class="p">:</span><span class="w"> </span><span class="l">common </span><span class="w"> </span><span class="c"># 使用专用节点组，如果希望使用多个节点组，可改用节点亲和性</span><span class="w">
</span><span class="w">      </span><span class="nt">volumes</span><span class="p">:</span><span class="w">
</span><span class="w">      </span>- <span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">tmp-dir</span><span class="w">
</span><span class="w">        </span><span class="nt">emptyDir</span><span class="p">:</span><span class="w"> </span>{}<span class="w">
</span><span class="w">      </span><span class="nt">containers</span><span class="p">:</span><span class="w">
</span><span class="w">      </span>- <span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">my-app-v3</span><span class="w">
</span><span class="w">        </span><span class="nt">image</span><span class="p">:</span><span class="w"> </span><span class="l">my-app:v3 </span><span class="w"> </span><span class="c"># 建议使用私有镜像仓库，规避 docker.io 的镜像拉取限制</span><span class="w">
</span><span class="w">        </span><span class="nt">imagePullPolicy</span><span class="p">:</span><span class="w"> </span><span class="l">IfNotPresent</span><span class="w">
</span><span class="w">        </span><span class="nt">volumeMounts</span><span class="p">:</span><span class="w">
</span><span class="w">        </span>- <span class="nt">mountPath</span><span class="p">:</span><span class="w"> </span><span class="l">/tmp</span><span class="w">
</span><span class="w">          </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">tmp-dir</span><span class="w">
</span><span class="w">        </span><span class="nt">lifecycle</span><span class="p">:</span><span class="w">
</span><span class="w">          </span><span class="nt">preStop</span><span class="p">:</span><span class="w">
</span><span class="w">            </span><span class="nt">exec</span><span class="p">:</span><span class="w">
</span><span class="w">              </span><span class="nt">command</span><span class="p">:</span><span class="w">
</span><span class="w">              </span>- <span class="l">/bin/sh</span><span class="w">
</span><span class="w">              </span>- -<span class="l">c</span><span class="w">
</span><span class="w">              </span>- <span class="s2">&#34;while [ $(netstat -plunt | grep tcp | wc -l | xargs) -ne 0 ]; do sleep 1; done&#34;</span><span class="w">
</span><span class="w">        </span><span class="nt">resources</span><span class="p">:</span><span class="w">  </span><span class="c"># 资源请求与限制</span><span class="w">
</span><span class="w">          </span><span class="c"># 对于核心服务，建议设置 requests = limits，避免资源竞争</span><span class="w">
</span><span class="w">          </span><span class="nt">requests</span><span class="p">:</span><span class="w">
</span><span class="w">            </span><span class="c"># HPA 会使用 requests 计算资源利用率</span><span class="w">
</span><span class="w">            </span><span class="c"># 建议将 requests 设为服务正常状态下的 CPU 使用率，HPA 的目前指标设为 80%</span><span class="w">
</span><span class="w">            </span><span class="c"># 所有容器的 requests 总量不建议为 2c/4G 4c/8G 等常见值，因为节点通常也是这个配置，这会导致 Pod 只能调度到更大的节点上，适当调小 requests 等扩充可用的节点类型，从而扩充节点池。 </span><span class="w">
</span><span class="w">            </span><span class="nt">cpu</span><span class="p">:</span><span class="w"> </span><span class="l">1000m</span><span class="w">
</span><span class="w">            </span><span class="nt">memory</span><span class="p">:</span><span class="w"> </span><span class="l">1Gi</span><span class="w">
</span><span class="w">          </span><span class="nt">limits</span><span class="p">:</span><span class="w">
</span><span class="w">            </span><span class="c"># limits - requests 为允许超卖的资源量，建议为 requests 的 1 到 2 倍，酌情配置。</span><span class="w">
</span><span class="w">            </span><span class="nt">cpu</span><span class="p">:</span><span class="w"> </span><span class="l">1000m</span><span class="w">
</span><span class="w">            </span><span class="nt">memory</span><span class="p">:</span><span class="w"> </span><span class="l">1Gi</span><span class="w">
</span><span class="w">        </span><span class="nt">securityContext</span><span class="p">:</span><span class="w">
</span><span class="w">          </span><span class="c"># 将容器层设为只读，防止容器文件被篡改</span><span class="w">
</span><span class="w">          </span><span class="c">## 如果需要写入临时文件，建议额外挂载 emptyDir 来提供可读写的数据卷</span><span class="w">
</span><span class="w">          </span><span class="nt">readOnlyRootFilesystem</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span><span class="w">
</span><span class="w">          </span><span class="c"># 禁止 Pod 做任何权限提升</span><span class="w">
</span><span class="w">          </span><span class="nt">allowPrivilegeEscalation</span><span class="p">:</span><span class="w"> </span><span class="kc">false</span><span class="w">
</span><span class="w">          </span><span class="nt">capabilities</span><span class="p">:</span><span class="w">
</span><span class="w">            </span><span class="c"># drop ALL 的权限比较严格，可按需修改</span><span class="w">
</span><span class="w">            </span><span class="nt">drop</span><span class="p">:</span><span class="w">
</span><span class="w">            </span>- <span class="l">ALL</span><span class="w">
</span><span class="w">        </span><span class="nt">startupProbe</span><span class="p">:</span><span class="w">  </span><span class="c"># 要求 kubernetes 1.18+</span><span class="w">
</span><span class="w">          </span><span class="nt">httpGet</span><span class="p">:</span><span class="w">
</span><span class="w">            </span><span class="nt">path</span><span class="p">:</span><span class="w"> </span><span class="l">/actuator/health </span><span class="w"> </span><span class="c"># 直接使用健康检查接口即可</span><span class="w">
</span><span class="w">            </span><span class="nt">port</span><span class="p">:</span><span class="w"> </span><span class="m">8080</span><span class="w">
</span><span class="w">          </span><span class="nt">periodSeconds</span><span class="p">:</span><span class="w"> </span><span class="m">5</span><span class="w">
</span><span class="w">          </span><span class="nt">timeoutSeconds</span><span class="p">:</span><span class="w"> </span><span class="m">1</span><span class="w">
</span><span class="w">          </span><span class="nt">failureThreshold</span><span class="p">:</span><span class="w"> </span><span class="m">20</span><span class="w">  </span><span class="c"># 最多提供给服务 5s * 20 的启动时间</span><span class="w">
</span><span class="w">          </span><span class="nt">successThreshold</span><span class="p">:</span><span class="w"> </span><span class="m">1</span><span class="w">
</span><span class="w">        </span><span class="nt">livenessProbe</span><span class="p">:</span><span class="w">
</span><span class="w">          </span><span class="nt">httpGet</span><span class="p">:</span><span class="w">
</span><span class="w">            </span><span class="nt">path</span><span class="p">:</span><span class="w"> </span><span class="l">/actuator/health </span><span class="w"> </span><span class="c"># spring 的通用健康检查路径</span><span class="w">
</span><span class="w">            </span><span class="nt">port</span><span class="p">:</span><span class="w"> </span><span class="m">8080</span><span class="w">
</span><span class="w">          </span><span class="nt">periodSeconds</span><span class="p">:</span><span class="w"> </span><span class="m">5</span><span class="w">
</span><span class="w">          </span><span class="nt">timeoutSeconds</span><span class="p">:</span><span class="w"> </span><span class="m">1</span><span class="w">
</span><span class="w">          </span><span class="nt">failureThreshold</span><span class="p">:</span><span class="w"> </span><span class="m">5</span><span class="w">
</span><span class="w">          </span><span class="nt">successThreshold</span><span class="p">:</span><span class="w"> </span><span class="m">1</span><span class="w">
</span><span class="w">        </span><span class="c"># Readiness probes are very important for a RollingUpdate to work properly,</span><span class="w">
</span><span class="w">        </span><span class="nt">readinessProbe</span><span class="p">:</span><span class="w">
</span><span class="w">          </span><span class="nt">httpGet</span><span class="p">:</span><span class="w">
</span><span class="w">            </span><span class="nt">path</span><span class="p">:</span><span class="w"> </span><span class="l">/actuator/health </span><span class="w"> </span><span class="c"># 简单起见可直接使用 livenessProbe 相同的接口，当然也可额外定义</span><span class="w">
</span><span class="w">            </span><span class="nt">port</span><span class="p">:</span><span class="w"> </span><span class="m">8080</span><span class="w">
</span><span class="w">          </span><span class="nt">periodSeconds</span><span class="p">:</span><span class="w"> </span><span class="m">5</span><span class="w">
</span><span class="w">          </span><span class="nt">timeoutSeconds</span><span class="p">:</span><span class="w"> </span><span class="m">1</span><span class="w">
</span><span class="w">          </span><span class="nt">failureThreshold</span><span class="p">:</span><span class="w"> </span><span class="m">5</span><span class="w">
</span><span class="w">          </span><span class="nt">successThreshold</span><span class="p">:</span><span class="w"> </span><span class="m">1</span><span class="w">
</span><span class="w"></span><span class="nn">---</span><span class="w">
</span><span class="w"></span><span class="nt">apiVersion</span><span class="p">:</span><span class="w"> </span><span class="l">autoscaling/v2beta2</span><span class="w">
</span><span class="w"></span><span class="nt">kind</span><span class="p">:</span><span class="w"> </span><span class="l">HorizontalPodAutoscaler</span><span class="w">
</span><span class="w"></span><span class="nt">metadata</span><span class="p">:</span><span class="w">
</span><span class="w">  </span><span class="nt">labels</span><span class="p">:</span><span class="w">
</span><span class="w">    </span><span class="nt">app</span><span class="p">:</span><span class="w"> </span><span class="l">my-app</span><span class="w">
</span><span class="w">  </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">my-app-v3</span><span class="w">
</span><span class="w">  </span><span class="nt">namespace</span><span class="p">:</span><span class="w"> </span><span class="l">prod</span><span class="w">
</span><span class="w"></span><span class="nt">spec</span><span class="p">:</span><span class="w">
</span><span class="w">  </span><span class="nt">scaleTargetRef</span><span class="p">:</span><span class="w">
</span><span class="w">    </span><span class="nt">apiVersion</span><span class="p">:</span><span class="w"> </span><span class="l">apps/v1</span><span class="w">
</span><span class="w">    </span><span class="nt">kind</span><span class="p">:</span><span class="w"> </span><span class="l">Deployment</span><span class="w">
</span><span class="w">    </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">my-app-v3</span><span class="w">
</span><span class="w">  </span><span class="nt">maxReplicas</span><span class="p">:</span><span class="w"> </span><span class="m">50</span><span class="w">
</span><span class="w">  </span><span class="nt">minReplicas</span><span class="p">:</span><span class="w"> </span><span class="m">3</span><span class="w">
</span><span class="w">  </span><span class="nt">metrics</span><span class="p">:</span><span class="w">
</span><span class="w">  </span>- <span class="nt">type</span><span class="p">:</span><span class="w"> </span><span class="l">Resource</span><span class="w">
</span><span class="w">    </span><span class="nt">resource</span><span class="p">:</span><span class="w">
</span><span class="w">      </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">cpu</span><span class="w">
</span><span class="w">      </span><span class="nt">target</span><span class="p">:</span><span class="w">
</span><span class="w">        </span><span class="nt">type</span><span class="p">:</span><span class="w"> </span><span class="l">Utilization</span><span class="w">
</span><span class="w">        </span><span class="nt">averageUtilization</span><span class="p">:</span><span class="w"> </span><span class="m">70</span><span class="w">
</span><span class="w"></span><span class="nn">---</span><span class="w">
</span><span class="w"></span><span class="nt">apiVersion</span><span class="p">:</span><span class="w"> </span><span class="l">policy/v1</span><span class="w">
</span><span class="w"></span><span class="nt">kind</span><span class="p">:</span><span class="w"> </span><span class="l">PodDisruptionBudget</span><span class="w">
</span><span class="w"></span><span class="nt">metadata</span><span class="p">:</span><span class="w">
</span><span class="w">  </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">my-app-v3</span><span class="w">
</span><span class="w">  </span><span class="nt">namespace</span><span class="p">:</span><span class="w"> </span><span class="l">prod</span><span class="w">
</span><span class="w">  </span><span class="nt">labels</span><span class="p">:</span><span class="w">
</span><span class="w">    </span><span class="nt">app</span><span class="p">:</span><span class="w"> </span><span class="l">my-app</span><span class="w">
</span><span class="w"></span><span class="nt">spec</span><span class="p">:</span><span class="w">
</span><span class="w">  </span><span class="nt">minAvailable</span><span class="p">:</span><span class="w"> </span><span class="m">75</span><span class="l">%</span><span class="w">
</span><span class="w">  </span><span class="nt">selector</span><span class="p">:</span><span class="w">
</span><span class="w">    </span><span class="nt">matchLabels</span><span class="p">:</span><span class="w">
</span><span class="w">      </span><span class="nt">app</span><span class="p">:</span><span class="w"> </span><span class="l">my-app</span><span class="w">
</span><span class="w">      </span><span class="nt">version</span><span class="p">:</span><span class="w"> </span><span class="l">v3</span><span class="w">
</span></code></pre></td></tr></table>
</div>
</div><h2 id="一优雅停止gracful-shutdown与-502504-报错">一、优雅停止（Gracful Shutdown）与 502/504 报错</h2>
<p>如果 Pod 正在处理大量请求（比如 1000 QPS+）时，因为节点故障或「竞价节点」被回收等原因被重新调度，
你可能会观察到在容器被 terminate 的一段时间内出现少量 502/504。</p>
<p>为了搞清楚这个问题，需要先理解清楚 terminate 一个 Pod 的流程：</p>
<ol>
<li>Pod 的状态被设为「Terminating」，（几乎）同时该 Pod 被从所有关联的 Service Endpoints 中移除</li>
<li><code>preStop</code> 钩子被执行，它可以是一个命令，或者一个对 Pod 中容器的 http 调用
<ol>
<li>如果你的程序在收到 SIGTERM 信号时，无法优雅退出，就可以考虑使用 <code>preStop</code></li>
<li>如果让程序本身支持优雅退出比较麻烦的话，用 <code>preStop</code> 实现优雅退出是一个非常好的方式</li>
</ol>
</li>
<li>将 SIGTERM 发送给 Pod 中的所有容器</li>
<li>继续等待，直到超过 <code>spec.terminationGracePeriodSeconds</code> 设定好的时间，这个值默认为 30s
<ol>
<li>需要注意的是，这个优雅退出的等待计时是与 <code>preStop</code> 同步开始的！而且它也不会等待 <code>preStop</code> 结束！</li>
</ol>
</li>
<li>如果超过了 <code>spec.terminationGracePeriodSeconds</code> 容器仍然没有停止，k8s 将会发送 SIGKILL 信号给容器</li>
<li>进程全部终止后，整个 Pod 完全被清理掉</li>
</ol>
<p><strong>注意</strong>：1 和 2 两个工作是异步发生的，所以可能会出现「Pod 还在 Service Endpoints 中，但是 <code>preStop</code> 已经执行了」的情况，我们需要考虑到这种状况的发生。</p>
<p>了解了上面的流程后，我们就能分析出两种错误码出现的原因：</p>
<ul>
<li>502：应用程序在收到 SIGTERM 信号后直接终止了运行，导致部分还没有被处理完的请求直接中断，代理层返回 502 表示这种情况</li>
<li>504：Service Endpoints 移除不够及时，在 Pod 已经被终止后，仍然有个别请求被路由到了该 Pod，得不到响应导致 504</li>
</ul>
<p>通常的解决方案是，在 Pod 的 <code>preStop</code> 步骤加一个 15s 的等待时间。
其原理是：在 Pod 处理 terminating 状态的时候，就会被从 Service Endpoints 中移除，也就不会再有新的请求过来了。
在 <code>preStop</code> 等待 15s，基本就能保证所有的请求都在容器死掉之前被处理完成（一般来说，绝大部分请求的处理时间都在 300ms 以内吧）。</p>
<p>一个简单的示例如下，它使 Pod 被终止时，总是先等待 15s，再发送 SIGTERM 信号给容器：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span><span class="lnt">8
</span><span class="lnt">9
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-yaml" data-lang="yaml"><span class="w">    </span><span class="nt">containers</span><span class="p">:</span><span class="w">
</span><span class="w">    </span>- <span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">my-app</span><span class="w">
</span><span class="w">      </span><span class="c"># 添加下面这部分</span><span class="w">
</span><span class="w">      </span><span class="nt">lifecycle</span><span class="p">:</span><span class="w">
</span><span class="w">        </span><span class="nt">preStop</span><span class="p">:</span><span class="w">
</span><span class="w">          </span><span class="nt">exec</span><span class="p">:</span><span class="w">
</span><span class="w">            </span><span class="nt">command</span><span class="p">:</span><span class="w">
</span><span class="w">            </span>- <span class="l">/bin/sleep</span><span class="w">
</span><span class="w">            </span>- <span class="s2">&#34;15&#34;</span><span class="w">
</span></code></pre></td></tr></table>
</div>
</div><p>更好的解决办法，是直接等待所有 tcp 连接都关闭（需要镜像中有 netstat）：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-yaml" data-lang="yaml"><span class="w">    </span><span class="nt">containers</span><span class="p">:</span><span class="w">
</span><span class="w">    </span>- <span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">my-app</span><span class="w">
</span><span class="w">      </span><span class="c"># 添加下面这部分</span><span class="w">
</span><span class="w">      </span><span class="nt">lifecycle</span><span class="p">:</span><span class="w">
</span><span class="w">      </span><span class="nt">preStop</span><span class="p">:</span><span class="w">
</span><span class="w">          </span><span class="nt">exec</span><span class="p">:</span><span class="w">
</span><span class="w">            </span><span class="nt">command</span><span class="p">:</span><span class="w">
</span><span class="w">            </span>- <span class="l">/bin/sh</span><span class="w">
</span><span class="w">            </span>- -<span class="l">c</span><span class="w">
</span><span class="w">            </span>- <span class="s2">&#34;while [ $(netstat -plunt | grep tcp | wc -l | xargs) -ne 0 ]; do sleep 1; done&#34;</span><span class="w">
</span></code></pre></td></tr></table>
</div>
</div><h3 id="参考">参考</h3>
<ul>
<li><a href="https://cloud.google.com/blog/products/containers-kubernetes/kubernetes-best-practices-terminating-with-grace" target="_blank" rel="noopener noreferrer">Kubernetes best practices: terminating with grace</a></li>
<li><a href="https://medium.com/flant-com/kubernetes-graceful-shutdown-nginx-php-fpm-d5ab266963c2" target="_blank" rel="noopener noreferrer">Graceful shutdown in Kubernetes is not always trivial</a></li>
</ul>
<h2 id="二服务的伸缩配置---hpa">二、服务的伸缩配置 - HPA</h2>
<p>Kubernetes 官方主要支持基于 Pod CPU 的伸缩，这是应用最为广泛的伸缩指标，需要部署 <a href="https://github.com/kubernetes-sigs/metrics-server" target="_blank" rel="noopener noreferrer">metrics-server</a> 才可使用。</p>
<p>先回顾下前面给出的示例：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-yaml" data-lang="yaml"><span class="nt">apiVersion</span><span class="p">:</span><span class="w"> </span><span class="l">autoscaling/v2beta2 </span><span class="w"> </span><span class="c"># k8s 1.23+ 此 API 已经 GA</span><span class="w">
</span><span class="w"></span><span class="nt">kind</span><span class="p">:</span><span class="w"> </span><span class="l">HorizontalPodAutoscaler</span><span class="w">
</span><span class="w"></span><span class="nt">metadata</span><span class="p">:</span><span class="w">
</span><span class="w">  </span><span class="nt">labels</span><span class="p">:</span><span class="w">
</span><span class="w">    </span><span class="nt">app</span><span class="p">:</span><span class="w"> </span><span class="l">my-app</span><span class="w">
</span><span class="w">  </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">my-app-v3</span><span class="w">
</span><span class="w">  </span><span class="nt">namespace</span><span class="p">:</span><span class="w"> </span><span class="l">prod</span><span class="w">
</span><span class="w"></span><span class="nt">spec</span><span class="p">:</span><span class="w">
</span><span class="w">  </span><span class="nt">scaleTargetRef</span><span class="p">:</span><span class="w">
</span><span class="w">    </span><span class="nt">apiVersion</span><span class="p">:</span><span class="w"> </span><span class="l">apps/v1</span><span class="w">
</span><span class="w">    </span><span class="nt">kind</span><span class="p">:</span><span class="w"> </span><span class="l">Deployment</span><span class="w">
</span><span class="w">    </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">my-app-v3</span><span class="w">
</span><span class="w">  </span><span class="nt">maxReplicas</span><span class="p">:</span><span class="w"> </span><span class="m">50</span><span class="w">
</span><span class="w">  </span><span class="nt">minReplicas</span><span class="p">:</span><span class="w"> </span><span class="m">3</span><span class="w">
</span><span class="w">  </span><span class="nt">metrics</span><span class="p">:</span><span class="w">
</span><span class="w">  </span>- <span class="nt">type</span><span class="p">:</span><span class="w"> </span><span class="l">Resource</span><span class="w">
</span><span class="w">    </span><span class="nt">resource</span><span class="p">:</span><span class="w">
</span><span class="w">      </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">cpu</span><span class="w">
</span><span class="w">      </span><span class="nt">target</span><span class="p">:</span><span class="w">
</span><span class="w">        </span><span class="nt">type</span><span class="p">:</span><span class="w"> </span><span class="l">Utilization</span><span class="w">
</span><span class="w">        </span><span class="nt">averageUtilization</span><span class="p">:</span><span class="w"> </span><span class="m">70</span><span class="w">
</span></code></pre></td></tr></table>
</div>
</div><h3 id="1-当前指标值的计算方式">1. 当前指标值的计算方式</h3>
<p>HPA 默认使用 Pod 的当前指标进行计算，以 CPU 为例，其计算公式为：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-fallback" data-lang="fallback">「Pod 的 CPU 利用率」= 100% * 「所有 Container 的 CPU 用量之和」/「所有 Container 的 CPU requests 之和」
</code></pre></td></tr></table>
</div>
</div><p>注意分母是总的 requests 量，而不是 limits.</p>
<h4 id="11-存在的问题与解决方法">1.1 存在的问题与解决方法</h4>
<p>在 Pod 只有一个容器时这没啥问题，但是当 Pod 注入了 envoy 等 sidecar 时，这就会有问题了。</p>
<p>因为 Istio 的 Sidecar requests 默认为 <code>100m</code> 也就是 0.1 核。
在未 tuning 的情况下，服务负载一高，sidecar 的实际用量很容易就能涨到 0.2-0.4 核。
把这两个值代入前面的公式，会发现 <strong>对于 QPS 较高的服务，添加 Sidecar 后，「Pod 的 CPU 利用率」可能会高于「应用容器的 CPU 利用率」</strong>，造成不必要的扩容。</p>
<p>解决方法：</p>
<ul>
<li>方法一：针对每个服务的 CPU 使用情况，为 sidecar 设置不同的 requests/limits</li>
<li>方法二：使用 KEDA 等第三方组件，获取到应用程序的 CPU 利用率（排除掉 Sidecar），使用它进行扩缩容</li>
<li>方法三：使用 k8s 1.20 提供的 alpha 特性：<a href="https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/#container-resource-metrics" target="_blank" rel="noopener noreferrer">Container Resourse Metrics</a>.</li>
</ul>
<h4 id="2-hpa-的扩缩容算法">2. HPA 的扩缩容算法</h4>
<p>HPA 什么时候会扩容，这一点是很好理解的。但是 HPA 的缩容策略，会有些迷惑，下面简单分析下。</p>
<ol>
<li>HPA 的「目标指标」可以使用两种形式：绝对度量指标和资源利用率。
<ul>
<li>绝对度量指标：比如 CPU，就是设定绝对核数。</li>
<li>资源利用率（资源使用量/资源请求 * 100%）：在 Pod 设置了资源请求时，可以使用资源利用率进行 Pod 伸缩。</li>
</ul>
</li>
<li>HPA 的「当前指标」是一段时间内所有 Pods 的平均值，不是峰值。Pod 的指标是其中所有容器指标之和。</li>
</ol>
<p>HPA 的扩缩容算法为：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-fallback" data-lang="fallback">期望副本数 = ceil[当前副本数 * ( 当前指标 / 目标指标 )]
</code></pre></td></tr></table>
</div>
</div><p>从上面的参数可以看到：</p>
<ol>
<li>只要「当前指标」超过了目标指标，就一定会发生扩容。</li>
<li><code>当前指标 / 目标指标</code>要小到一定的程度，才会触发缩容。
<ol>
<li>比如双副本的情况下，上述比值要小于等于 1/2，才会缩容到单副本。</li>
<li>三副本的情况下，上述比值的临界点是 2/3。</li>
<li>五副本时临界值是 4/5，100副本时临界值是 99/100，依此类推。</li>
<li>如果 <code>当前指标 / 目标指标</code> 从 1 降到 0.5，副本的数量将会减半。（虽然说副本数越多，发生这么大变化的可能性就越小。）</li>
</ol>
</li>
<li><code>当前副本数 / 目标指标</code>的值越大，「当前指标」的波动对「期望副本数」的影响就越大。</li>
</ol>
<p>为了防止扩缩容过于敏感，它还有几个延时相关的参数：</p>
<ol>
<li>HPA Loop 延时：默认 15 秒，每 15 秒钟进行一次 HPA 扫描。</li>
<li><code>--horizontal-pod-autoscaler-cpu-initialization-period</code>:</li>
<li>缩容冷却时间：默认 5 分钟。</li>
</ol>
<h3 id="3-hpa-的期望值设成多少合适">3. HPA 的期望值设成多少合适</h3>
<p>这个需要针对每个服务的具体情况，具体分析。</p>
<p>以最常用的按 CPU 值伸缩为例，</p>
<ul>
<li>核心服务
<ul>
<li>requests/limits 值: 建议设成相等的，保证<a href="https://kubernetes.io/docs/tasks/configure-pod-container/quality-service-pod/" target="_blank" rel="noopener noreferrer">服务质量等级</a>为 Guaranteed
<ul>
<li>需要注意 CPU 跟 Memory 的 limits 限制策略是不同的，CPU 是真正地限制了上限，而 Memory 是用超了就干掉容器（OOMKilled）</li>
<li>k8s 一直使用 cgroups v1 (<code>cpu_shares</code>/<code>memory.limit_in_bytes</code>)来限制 cpu/memory，但是对于 <code>Guaranteed</code> 的 Pods 而言，内存并不能完全预留，资源竞争总是有可能发生的。1.22 有 alpha 特性改用 cgroups v2，可以关注下。</li>
</ul>
</li>
<li>HPA: 一般来说，期望值设为 60% 到 70% 可能是比较合适的，最小副本数建议设为 2 - 5. （仅供参考）</li>
<li>PodDisruptionBudget: 建议按服务的健壮性与 HPA 期望值，来设置 PDB，后面会详细介绍，这里就先略过了</li>
</ul>
</li>
<li>非核心服务
<ul>
<li>requests/limits 值: 建议 requests 设为 limits 的 0.6 - 0.9 倍（仅供参考），对应的服务质量等级为 Burstable
<ul>
<li>也就是超卖了资源，这样做主要的考量点是，很多非核心服务负载都很低，根本跑不到 limits 这么高，降低 requests 可以提高集群资源利用率，也不会损害服务稳定性。</li>
</ul>
</li>
<li>HPA: 因为 requests 降低了，我们可以提高 HPA 到期望值，比如 80% ~ 90%，最小副本数建议设为 1 - 3. （仅供参考）</li>
<li>PodDisruptionBudget: 非核心服务嘛，保证最少副本数为 1 就行了。</li>
</ul>
</li>
</ul>
<h3 id="4-hpa-的常见问题">4. HPA 的常见问题</h3>
<h4 id="41-pod-扩容---预热陷阱">4.1. Pod 扩容 - 预热陷阱</h4>
<blockquote>
<p>预热：Java/C# 这类运行在虚拟机上的语言，第一次使用到某些功能时，往往需要初始化一些资源，例如「JIT 即时编译」。
如果代码里还应用了动态类加载之类的功能，就很可能导致微服务某些 API 第一次被调用时，响应特别慢（要动态编译 class）。
因此 Pod 在提供服务前，需要提前「预热（slow_start）」一次这些接口，将需要用到的资源提前初始化好。</p>
</blockquote>
<p>在负载很高的情况下，HPA 会自动扩容。
但是如果扩容的 Pod 需要预热，就可能会遇到「预热陷阱」。</p>
<p>在有大量用户访问的时候，不论使用何种负载均衡策略，只要请求被转发到新建的 Pod 上，这个请求就会「卡住」。
如果请求速度太快，Pod 启动的瞬间「卡住」的请求就越多，这将会导致新建 Pod 因为压力过大而垮掉。
然后 Pod 一重启就被压垮，进入 CrashLoopBackoff 循环。</p>
<p>如果是在使用多线程做负载测试时，效果更明显：50 个线程在不间断地请求，
别的 Pod 响应时间是「毫秒级」，而新建的 Pod 的首次响应是「秒级」。几乎是一瞬间，50 个线程就会全部陷在新建的 Pod 这里。
而新建的 Pod 在启动的瞬间可能特别脆弱，瞬间的 50 个并发请求就可以将它压垮。
然后 Pod 一重启就被压垮，进入 CrashLoopBackoff 循环。</p>
<p><strong>解决方法</strong>：</p>
<p>可以在「应用层面」解决：</p>
<ol>
<li>在启动探针 API 的后端控制器里面，依次调用所有需要预热的接口或者其他方式，提前初始化好所有资源。
<ol>
<li>启动探针的控制器中，可以通过 <code>localhost</code> 回环地址调用它自身的接口。</li>
</ol>
</li>
<li>使用「AOT 预编译」技术：预热，通常都是因为「JIT 即时编译」导致的问题，在需要用到时它才编译。而 AOT 是预先编译，在使用前完成编译，因此 AOT 能解决预热的问题。</li>
</ol>
<p>也可以在「基础设施层面」解决：</p>
<ol>
<li>像 AWS ALB TargetGroup 以及其他云服务商的 ALB 服务，通常都可以设置 <code>slow_start</code> 时长，即对新加入的实例，使用一定时间慢慢地把流量切过去，最终达到预期的负载均衡状态。这个可以解决服务预热问题。</li>
<li>Envoy 也已经支持 <code>slow_start</code> 模式，支持在一个设置好的时间窗口内，把流量慢慢负载到新加入的实例上，达成预热效果。</li>
</ol>
<h4 id="42-hpa-扩缩容过于敏感导致-pod-数量震荡">4.2. HPA 扩缩容过于敏感，导致 Pod 数量震荡</h4>
<p>通常来讲，EKS 上绝大部分负载都应该选择使用 CPU 进行扩缩容。因为 CPU 通常能很好的反映服务的负载情况</p>
<p>但是有些服务会存在其他影响 CPU 使用率的因素，导致使用 CPU 扩缩容变得不那么可靠，比如：</p>
<ul>
<li>有些 Java 服务堆内存设得很大，GC pause 也设得比较长，因此内存 GC 会造成 CPU 间歇性飙升，CPU 监控会有大量的尖峰。</li>
<li>有些服务有定时任务，定时任务一运行 CPU 就涨，但是这跟服务的 QPS 是无关的</li>
<li>有些服务可能一运行 CPU 就会立即处于一个高位状态，它可能希望使用别的业务侧指标来进行扩容，而不是 CPU.</li>
</ul>
<p>因为上述问题存在，使用 CPU 扩缩容，就可能会造成服务频繁的扩容然后缩容，或者无限扩容。
而有些服务（如我们的「推荐服务」），对「扩容」和「缩容」都是比较敏感的，每次扩缩都会造成服务可用率抖动。</p>
<p>对这类服务而言，HPA 有这几种调整策略：</p>
<ul>
<li>选择使用 <strong>QPS</strong> 等相对比较平滑，没有 GC 这类干扰的指标来进行扩缩容，这需要借助 KEDA 等社区组件。</li>
<li>对 kubernetes 1.18+，可以直接使用 HPA 的 <code>behavior.scaleDown</code> 和 <code>behavior.scaleUp</code> 两个参数，控制每次扩缩容的最多 pod 数量或者比例。 示例如下：</li>
</ul>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span><span class="lnt">38
</span><span class="lnt">39
</span><span class="lnt">40
</span><span class="lnt">41
</span><span class="lnt">42
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-yaml" data-lang="yaml"><span class="nn">---</span><span class="w">
</span><span class="w"></span><span class="nt">apiVersion</span><span class="p">:</span><span class="w"> </span><span class="l">autoscaling/v2beta2</span><span class="w">
</span><span class="w"></span><span class="nt">kind</span><span class="p">:</span><span class="w"> </span><span class="l">HorizontalPodAutoscaler</span><span class="w">
</span><span class="w"></span><span class="nt">metadata</span><span class="p">:</span><span class="w">
</span><span class="w">  </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">podinfo</span><span class="w">
</span><span class="w">  </span><span class="nt">namespace</span><span class="p">:</span><span class="w"> </span><span class="l">default</span><span class="w">
</span><span class="w"></span><span class="nt">spec</span><span class="p">:</span><span class="w">
</span><span class="w">  </span><span class="nt">scaleTargetRef</span><span class="p">:</span><span class="w">
</span><span class="w">    </span><span class="nt">apiVersion</span><span class="p">:</span><span class="w"> </span><span class="l">apps/v1</span><span class="w">
</span><span class="w">    </span><span class="nt">kind</span><span class="p">:</span><span class="w"> </span><span class="l">Deployment</span><span class="w">
</span><span class="w">    </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">podinfo</span><span class="w">
</span><span class="w">  </span><span class="nt">minReplicas</span><span class="p">:</span><span class="w"> </span><span class="m">3</span><span class="w">
</span><span class="w">  </span><span class="nt">maxReplicas</span><span class="p">:</span><span class="w"> </span><span class="m">50</span><span class="w">
</span><span class="w">  </span><span class="nt">metrics</span><span class="p">:</span><span class="w">
</span><span class="w">  </span>- <span class="nt">type</span><span class="p">:</span><span class="w"> </span><span class="l">Resource</span><span class="w">
</span><span class="w">    </span><span class="nt">resource</span><span class="p">:</span><span class="w">
</span><span class="w">      </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">cpu</span><span class="w">
</span><span class="w">      </span><span class="nt">target</span><span class="p">:</span><span class="w">
</span><span class="w">        </span><span class="nt">type</span><span class="p">:</span><span class="w"> </span><span class="l">Utilization</span><span class="w">
</span><span class="w">        </span><span class="nt">averageUtilization</span><span class="p">:</span><span class="w"> </span><span class="m">50</span><span class="w">  </span><span class="c"># 期望的 CPU 平均值</span><span class="w">
</span><span class="w">  </span><span class="nt">behavior</span><span class="p">:</span><span class="w">
</span><span class="w">    </span><span class="nt">scaleUp</span><span class="p">:</span><span class="w">
</span><span class="w">      </span><span class="nt">stabilizationWindowSeconds</span><span class="p">:</span><span class="w"> </span><span class="m">0</span><span class="w">  </span><span class="c"># 默认为 0，只使用当前值进行扩缩容</span><span class="w">
</span><span class="w">      </span><span class="nt">policies</span><span class="p">:</span><span class="w">
</span><span class="w">      </span>- <span class="nt">periodSeconds</span><span class="p">:</span><span class="w"> </span><span class="m">180</span><span class="w">  </span><span class="c"># 每 3 分钟最多扩容 5% 的 Pods</span><span class="w">
</span><span class="w">        </span><span class="nt">type</span><span class="p">:</span><span class="w"> </span><span class="l">Percent</span><span class="w">
</span><span class="w">        </span><span class="nt">value</span><span class="p">:</span><span class="w"> </span><span class="m">5</span><span class="w">
</span><span class="w">      </span>- <span class="nt">periodSeconds</span><span class="p">:</span><span class="w"> </span><span class="m">60</span><span class="w">  </span><span class="c"># 每分钟最多扩容 1 个 Pod，扩的慢一点主要是为了一个个地预热，避免一次扩容太多未预热的 Pods 导致服务可用率剧烈抖动</span><span class="w">
</span><span class="w">        </span><span class="nt">type</span><span class="p">:</span><span class="w"> </span><span class="l">Pods</span><span class="w">
</span><span class="w">        </span><span class="nt">value</span><span class="p">:</span><span class="w"> </span><span class="m">1</span><span class="w">
</span><span class="w">      </span><span class="nt">selectPolicy</span><span class="p">:</span><span class="w"> </span><span class="l">Min </span><span class="w"> </span><span class="c"># 选择最小的策略</span><span class="w">
</span><span class="w">    </span><span class="c"># 以下的一切配置，都是为了更平滑地缩容</span><span class="w">
</span><span class="w">    </span><span class="nt">scaleDown</span><span class="p">:</span><span class="w">
</span><span class="w">      </span><span class="nt">stabilizationWindowSeconds</span><span class="p">:</span><span class="w"> </span><span class="m">600</span><span class="w">  </span><span class="c"># 使用过去 10 mins 的最大 cpu 值进行缩容计算，避免过快缩容</span><span class="w">
</span><span class="w">      </span><span class="nt">policies</span><span class="p">:</span><span class="w">
</span><span class="w">      </span>- <span class="nt">type</span><span class="p">:</span><span class="w"> </span><span class="l">Percent </span><span class="w"> </span><span class="c"># 每 3 mins 最多缩容 `ceil[当前副本数 * 5%]` 个 pod（20 个 pod 以内，一次只缩容 1 个 pod）</span><span class="w">
</span><span class="w">        </span><span class="nt">value</span><span class="p">:</span><span class="w"> </span><span class="m">5</span><span class="w">
</span><span class="w">        </span><span class="nt">periodSeconds</span><span class="p">:</span><span class="w"> </span><span class="m">180</span><span class="w">
</span><span class="w">      </span>- <span class="nt">type</span><span class="p">:</span><span class="w"> </span><span class="l">Pods </span><span class="w"> </span><span class="c"># 每 1 mins 最多缩容 1 个 pod</span><span class="w">
</span><span class="w">        </span><span class="nt">value</span><span class="p">:</span><span class="w"> </span><span class="m">1</span><span class="w">
</span><span class="w">        </span><span class="nt">periodSeconds</span><span class="p">:</span><span class="w"> </span><span class="m">60</span><span class="w">
</span><span class="w">      </span><span class="nt">selectPolicy</span><span class="p">:</span><span class="w"> </span><span class="l">Min </span><span class="w"> </span><span class="c"># 上面的 policies 列表，只生效其中最小的值作为缩容限制（保证平滑缩容）</span><span class="w">
</span></code></pre></td></tr></table>
</div>
</div><p>而对于扩容不够平滑这个问题，可以考虑提供类似 AWS ALB TargetGroup <code>slow_start</code> 的功能，在扩容时缓慢将流量切到新 Pod 上，以实现预热服务（JVM 预热以及本地缓存预热），这样就能达到比较好的平滑扩容效果。</p>
<h3 id="5-hpa-注意事项">5. HPA 注意事项</h3>
<p>注意 kubectl 1.23 以下的版本，默认使用 <code>hpa.v1.autoscaling</code> 来查询 HPA 配置，<code>v2beta2</code> 相关的参数会被编码到 <code>metadata.annotations</code> 中。</p>
<p>比如 <code>behavior</code> 就会被编码到 <code>autoscaling.alpha.kubernetes.io/behavior</code> 这个 key 所对应的值中。</p>
<p>因此如果使用了 v2beta2 的 HPA，一定要明确指定使用 <code>v2beta2</code> 版本的 HPA：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell">kubectl get hpa.v2beta2.autoscaling
</code></pre></td></tr></table>
</div>
</div><p>否则不小心动到 <code>annotations</code> 中编码的某些参数，可能会产生意料之外的效果，甚至直接把控制面搞崩&hellip;
比如这个 issue: <a href="https://github.com/kubernetes/kubernetes/issues/107038" target="_blank" rel="noopener noreferrer">Nil pointer dereference in KCM after v1 HPA patch request</a></p>
<h3 id="6-参考">6. 参考</h3>
<ul>
<li><a href="https://kubernetes.io/zh/docs/tasks/run-application/horizontal-pod-autoscale/" target="_blank" rel="noopener noreferrer">Pod 水平自动伸缩 - Kubernetes Docs</a></li>
<li><a href="https://kubernetes.io/zh/docs/tasks/run-application/horizontal-pod-autoscale-walkthrough/" target="_blank" rel="noopener noreferrer">Horizontal Pod Autoscaler演练 - Kubernetes Docs</a></li>
</ul>
<h2 id="三节点维护与pod干扰预算httpskubernetesiozhdocstasksrun-applicationconfigure-pdb">三、<a href="https://kubernetes.io/zh/docs/tasks/run-application/configure-pdb/" target="_blank" rel="noopener noreferrer">节点维护与Pod干扰预算</a></h2>
<p>在我们通过 <code>kubectl drain</code> 将某个节点上的容器驱逐走的时候，
kubernetes 会依据 Pod 的「PodDistruptionBuget」来进行 Pod 的驱逐。</p>
<p>如果不设置任何明确的 PodDistruptionBuget，Pod 将会被直接杀死，然后在别的节点重新调度，<strong>这可能导致服务中断！</strong></p>
<p>PDB 是一个单独的 CR 自定义资源，示例如下：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-yaml" data-lang="yaml"><span class="nt">apiVersion</span><span class="p">:</span><span class="w"> </span><span class="l">policy/v1beta1</span><span class="w">
</span><span class="w"></span><span class="nt">kind</span><span class="p">:</span><span class="w"> </span><span class="l">PodDisruptionBudget</span><span class="w">
</span><span class="w"></span><span class="nt">metadata</span><span class="p">:</span><span class="w">
</span><span class="w">  </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">podinfo-pdb</span><span class="w">
</span><span class="w"></span><span class="nt">spec</span><span class="p">:</span><span class="w">
</span><span class="w">  </span><span class="c"># 如果不满足 PDB，Pod 驱逐将会失败！</span><span class="w">
</span><span class="w">  </span><span class="nt">minAvailable</span><span class="p">:</span><span class="w"> </span><span class="m">1</span><span class="w">      </span><span class="c"># 最少也要维持一个 Pod 可用</span><span class="w">
</span><span class="w"></span><span class="c">#   maxUnavailable: 1  # 最大不可用的 Pod 数，与 minAvailable 不能同时配置！二选一</span><span class="w">
</span><span class="w">  </span><span class="nt">selector</span><span class="p">:</span><span class="w">
</span><span class="w">    </span><span class="nt">matchLabels</span><span class="p">:</span><span class="w">
</span><span class="w">      </span><span class="nt">app</span><span class="p">:</span><span class="w"> </span><span class="l">podinfo</span><span class="w">
</span></code></pre></td></tr></table>
</div>
</div><p>如果在进行节点维护时(kubectl drain)，Pod 不满足 PDB，drain 将会失败，示例：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell">&gt; kubectl drain node-205 --ignore-daemonsets --delete-local-data
node/node-205 cordoned
WARNING: ignoring DaemonSet-managed Pods: kube-system/calico-node-nfhj7, kube-system/kube-proxy-94dz5
evicting pod default/podinfo-7c84d8c94d-h9brq
evicting pod default/podinfo-7c84d8c94d-gw6qf
error when evicting pod <span class="s2">&#34;podinfo-7c84d8c94d-h9brq&#34;</span> <span class="o">(</span>will retry after 5s<span class="o">)</span>: Cannot evict pod as it would violate the pod<span class="s1">&#39;s disruption budget.
</span><span class="s1">evicting pod default/podinfo-7c84d8c94d-h9brq
</span><span class="s1">error when evicting pod &#34;podinfo-7c84d8c94d-h9brq&#34; (will retry after 5s): Cannot evict pod as it would violate the pod&#39;</span>s disruption budget.
evicting pod default/podinfo-7c84d8c94d-h9brq
error when evicting pod <span class="s2">&#34;podinfo-7c84d8c94d-h9brq&#34;</span> <span class="o">(</span>will retry after 5s<span class="o">)</span>: Cannot evict pod as it would violate the pod<span class="err">&#39;</span>s disruption budget.
evicting pod default/podinfo-7c84d8c94d-h9brq
pod/podinfo-7c84d8c94d-gw6qf evicted
pod/podinfo-7c84d8c94d-h9brq evicted
node/node-205 evicted
</code></pre></td></tr></table>
</div>
</div><p>上面的示例中，podinfo 一共有两个副本，都运行在 node-205 上面。我给它设置了干扰预算 PDB <code>minAvailable: 1</code>。</p>
<p>然后使用 <code>kubectl drain</code> 驱逐 Pod 时，其中一个 Pod 被立即驱逐走了，而另一个 Pod 大概在 15 秒内一直驱逐失败。
因为第一个 Pod 还没有在新的节点上启动完成，它不满足干扰预算 PDB <code>minAvailable: 1</code> 这个条件。</p>
<p>大约 15 秒后，最先被驱逐走的 Pod 在新节点上启动完成了，另一个 Pod 满足了 PDB 所以终于也被驱逐了。这才完成了一个节点的 drain 操作。</p>
<blockquote>
<p>ClusterAutoscaler 等集群节点伸缩组件，在缩容节点时也会考虑 PodDisruptionBudget. 如果你的集群使用了 ClusterAutoscaler 等动态扩缩容节点的组件，强烈建议设置为所有服务设置 PodDisruptionBudget.</p>
</blockquote>
<h4 id="在-pdb-中使用百分比的注意事项">在 PDB 中使用百分比的注意事项</h4>
<p>在使用百分比时，计算出的实例数都会被向上取整，这会造成两个现象：</p>
<ul>
<li>如果使用 <code>minAvailable</code>，实例数较少的情况下，可能会导致 ALLOWED DISRUPTIONS 为 0</li>
<li>如果使用 <code>maxUnavailable</code>，因为是向上取整，ALLOWED DISRUPTIONS 的值一定不会低于 1</li>
</ul>
<p>因此从便于驱逐的角度看，如果你的服务至少有 2-3 个实例，建议在 PDB 中使用百分比配置 <code>maxUnavailable</code>，而不是 <code>minAvailable</code>.</p>
<h3 id="最佳实践-deployment--hpa--poddisruptionbudget">最佳实践 Deployment + HPA + PodDisruptionBudget</h3>
<p>一般而言，一个服务的每个版本，都应该包含如下三个资源：</p>
<ul>
<li>Deployment: 管理服务自身的 Pods 嘛</li>
<li>HPA: 负责 Pods 的扩缩容，通常使用 CPU 指标进行扩缩容</li>
<li>PodDisruptionBudget(PDB): 建议按照 HPA 的目标值，来设置 PDB.
<ul>
<li>比如 HPA CPU 目标值为 60%，就可以考虑设置 PDB <code>minAvailable=65%</code>，保证至少有 65% 的 Pod 可用。这样理论上极限情况下 QPS 均摊到剩下 65% 的 Pods 上也不会造成雪崩（这里假设 QPS 和 CPU 是完全的线性关系）</li>
</ul>
</li>
</ul>
<h2 id="四节点亲和性与节点组">四、节点亲和性与节点组</h2>
<p>我们一个集群，通常会使用不同的标签为节点组进行分类，比如 kubernetes 自动生成的一些节点标签：</p>
<ul>
<li><code>kubernetes.io/os</code>: 通常都用 <code>linux</code></li>
<li><code>kubernetes.io/arch</code>: <code>amd64</code>, <code>arm64</code></li>
<li><code>topology.kubernetes.io/region</code> 和 <code>topology.kubernetes.io/zone</code>: 云服务的区域及可用区</li>
</ul>
<p>我们使用得比较多的，是「节点亲和性」以及「Pod 反亲和性」，另外两个策略视情况使用。</p>
<h3 id="1-节点亲和性">1. 节点亲和性</h3>
<p>如果你使用的是 aws，那 aws 有一些自定义的节点标签：</p>
<ul>
<li><code>eks.amazonaws.com/nodegroup</code>: aws eks 节点组的名称，同一个节点组使用同样的 aws ec2 实例模板
<ul>
<li>比如 arm64 节点组、amd64/x64 节点组</li>
<li>内存比例高的节点组如 m 系实例，计算性能高的节点组如 c 系列</li>
<li>竞价实例节点组：这个省钱啊，但是动态性很高，随时可能被回收</li>
<li>按量付费节点组：这类实例贵，但是稳定。</li>
</ul>
</li>
</ul>
<p>假设你希望优先选择竞价实例跑你的 Pod，如果竞价实例暂时跑满了，就选择按量付费实例。
那 <code>nodeSelector</code> 就满足不了你的需求了，你需要使用 <code>nodeAffinity</code>，示例如下:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span><span class="lnt">38
</span><span class="lnt">39
</span><span class="lnt">40
</span><span class="lnt">41
</span><span class="lnt">42
</span><span class="lnt">43
</span><span class="lnt">44
</span><span class="lnt">45
</span><span class="lnt">46
</span><span class="lnt">47
</span><span class="lnt">48
</span><span class="lnt">49
</span><span class="lnt">50
</span><span class="lnt">51
</span><span class="lnt">52
</span><span class="lnt">53
</span><span class="lnt">54
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-yaml" data-lang="yaml"><span class="nt">apiVersion</span><span class="p">:</span><span class="w"> </span><span class="l">apps/v1</span><span class="w">
</span><span class="w"></span><span class="nt">kind</span><span class="p">:</span><span class="w"> </span><span class="l">Deployment</span><span class="w">
</span><span class="w"></span><span class="nt">metadata</span><span class="p">:</span><span class="w">
</span><span class="w">  </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">xxx</span><span class="w">
</span><span class="w">  </span><span class="nt">namespace</span><span class="p">:</span><span class="w"> </span><span class="l">xxx</span><span class="w">
</span><span class="w"></span><span class="nt">spec</span><span class="p">:</span><span class="w">
</span><span class="w">  </span><span class="c"># ...</span><span class="w">
</span><span class="w">  </span><span class="nt">template</span><span class="p">:</span><span class="w">
</span><span class="w">    </span><span class="c"># ...</span><span class="w">
</span><span class="w">    </span><span class="nt">spec</span><span class="p">:</span><span class="w">
</span><span class="w">      </span><span class="nt">affinity</span><span class="p">:</span><span class="w">
</span><span class="w">        </span><span class="nt">nodeAffinity</span><span class="p">:</span><span class="w">
</span><span class="w">          </span><span class="c"># 优先选择 spot-group-c 的节点</span><span class="w">
</span><span class="w">          </span><span class="nt">preferredDuringSchedulingIgnoredDuringExecution</span><span class="p">:</span><span class="w">
</span><span class="w">          </span>- <span class="nt">preference</span><span class="p">:</span><span class="w">
</span><span class="w">              </span><span class="nt">matchExpressions</span><span class="p">:</span><span class="w">
</span><span class="w">              </span>- <span class="nt">key</span><span class="p">:</span><span class="w"> </span><span class="l">eks.amazonaws.com/nodegroup</span><span class="w">
</span><span class="w">                </span><span class="nt">operator</span><span class="p">:</span><span class="w"> </span><span class="l">In</span><span class="w">
</span><span class="w">                </span><span class="nt">values</span><span class="p">:</span><span class="w">
</span><span class="w">                </span>- <span class="l">spot-group-c</span><span class="w">
</span><span class="w">            </span><span class="nt">weight</span><span class="p">:</span><span class="w"> </span><span class="m">80</span><span class="w">  </span><span class="c"># weight 用于为节点评分，会优先选择评分最高的节点</span><span class="w">
</span><span class="w">          </span>- <span class="nt">preference</span><span class="p">:</span><span class="w">
</span><span class="w">              </span><span class="nt">matchExpressions</span><span class="p">:</span><span class="w">
</span><span class="w">              </span><span class="c"># 优先选择 aws c6i 的机器</span><span class="w">
</span><span class="w">              </span>- <span class="nt">key</span><span class="p">:</span><span class="w"> </span><span class="l">node.kubernetes.io/instance-type</span><span class="w">
</span><span class="w">                </span><span class="nt">operator</span><span class="p">:</span><span class="w"> </span><span class="l">In</span><span class="w">
</span><span class="w">                </span><span class="nt">values</span><span class="p">:</span><span class="w">
</span><span class="w">                </span>- <span class="s2">&#34;c6i.xlarge&#34;</span><span class="w">
</span><span class="w">                </span>- <span class="s2">&#34;c6i.2xlarge&#34;</span><span class="w">
</span><span class="w">                </span>- <span class="s2">&#34;c6i.4xlarge&#34;</span><span class="w">
</span><span class="w">                </span>- <span class="s2">&#34;c6i.8xlarge&#34;</span><span class="w">
</span><span class="w">            </span><span class="nt">weight</span><span class="p">:</span><span class="w"> </span><span class="m">70</span><span class="w">
</span><span class="w">          </span>- <span class="nt">preference</span><span class="p">:</span><span class="w">
</span><span class="w">              </span><span class="nt">matchExpressions</span><span class="p">:</span><span class="w">
</span><span class="w">              </span><span class="c"># 其次选择 aws c5 的机器</span><span class="w">
</span><span class="w">              </span>- <span class="nt">key</span><span class="p">:</span><span class="w"> </span><span class="l">node.kubernetes.io/instance-type</span><span class="w">
</span><span class="w">                </span><span class="nt">operator</span><span class="p">:</span><span class="w"> </span><span class="l">In</span><span class="w">
</span><span class="w">                </span><span class="nt">values</span><span class="p">:</span><span class="w">
</span><span class="w">                </span>- <span class="s2">&#34;c5.xlarge&#34;</span><span class="w">
</span><span class="w">                </span>- <span class="s2">&#34;c5.2xlarge&#34;</span><span class="w">
</span><span class="w">                </span>- <span class="s2">&#34;c5.4xlarge&#34;</span><span class="w">
</span><span class="w">                </span>- <span class="s2">&#34;c5.9xlarge&#34;</span><span class="w">
</span><span class="w">            </span><span class="nt">weight</span><span class="p">:</span><span class="w"> </span><span class="m">60</span><span class="w">
</span><span class="w">         </span><span class="c"># 如果没 spot-group-c 可用，也可选择 ondemand-group-c 的节点跑</span><span class="w">
</span><span class="w">          </span><span class="nt">requiredDuringSchedulingIgnoredDuringExecution</span><span class="p">:</span><span class="w">
</span><span class="w">            </span><span class="nt">nodeSelectorTerms</span><span class="p">:</span><span class="w">
</span><span class="w">            </span>- <span class="nt">matchExpressions</span><span class="p">:</span><span class="w">
</span><span class="w">              </span>- <span class="nt">key</span><span class="p">:</span><span class="w"> </span><span class="l">eks.amazonaws.com/nodegroup</span><span class="w">
</span><span class="w">                </span><span class="nt">operator</span><span class="p">:</span><span class="w"> </span><span class="l">In</span><span class="w">
</span><span class="w">                </span><span class="nt">values</span><span class="p">:</span><span class="w">
</span><span class="w">                </span>- <span class="l">spot-group-c</span><span class="w">
</span><span class="w">                </span>- <span class="l">ondemand-group-c</span><span class="w">
</span><span class="w">      </span><span class="nt">containers</span><span class="p">:</span><span class="w">
</span><span class="w">        </span><span class="c"># ...</span><span class="w">
</span></code></pre></td></tr></table>
</div>
</div><h3 id="2-pod-反亲和性">2. Pod 反亲和性</h3>
<p>通常建议为每个 Deployment 的 template 配置 Pod 反亲和性，把 Pods 打散在所有节点上：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span><span class="lnt">38
</span><span class="lnt">39
</span><span class="lnt">40
</span><span class="lnt">41
</span><span class="lnt">42
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-yaml" data-lang="yaml"><span class="nt">apiVersion</span><span class="p">:</span><span class="w"> </span><span class="l">apps/v1</span><span class="w">
</span><span class="w"></span><span class="nt">kind</span><span class="p">:</span><span class="w"> </span><span class="l">Deployment</span><span class="w">
</span><span class="w"></span><span class="nt">metadata</span><span class="p">:</span><span class="w">
</span><span class="w">  </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">xxx</span><span class="w">
</span><span class="w">  </span><span class="nt">namespace</span><span class="p">:</span><span class="w"> </span><span class="l">xxx</span><span class="w">
</span><span class="w"></span><span class="nt">spec</span><span class="p">:</span><span class="w">
</span><span class="w">  </span><span class="c"># ...</span><span class="w">
</span><span class="w">  </span><span class="nt">template</span><span class="p">:</span><span class="w">
</span><span class="w">    </span><span class="c"># ...</span><span class="w">
</span><span class="w">    </span><span class="nt">spec</span><span class="p">:</span><span class="w">
</span><span class="w">      </span><span class="nt">replicas</span><span class="p">:</span><span class="w"> </span><span class="m">3</span><span class="w">
</span><span class="w">      </span><span class="nt">affinity</span><span class="p">:</span><span class="w">
</span><span class="w">        </span><span class="nt">podAntiAffinity</span><span class="p">:</span><span class="w">
</span><span class="w">          </span><span class="nt">preferredDuringSchedulingIgnoredDuringExecution</span><span class="p">:</span><span class="w"> </span><span class="c"># 非强制性条件</span><span class="w">
</span><span class="w">          </span>- <span class="nt">weight</span><span class="p">:</span><span class="w"> </span><span class="m">100</span><span class="w">  </span><span class="c"># weight 用于为节点评分，会优先选择评分最高的节点</span><span class="w">
</span><span class="w">            </span><span class="nt">podAffinityTerm</span><span class="p">:</span><span class="w">
</span><span class="w">              </span><span class="nt">labelSelector</span><span class="p">:</span><span class="w">
</span><span class="w">                </span><span class="nt">matchExpressions</span><span class="p">:</span><span class="w">
</span><span class="w">                </span>- <span class="nt">key</span><span class="p">:</span><span class="w"> </span><span class="l">app</span><span class="w">
</span><span class="w">                  </span><span class="nt">operator</span><span class="p">:</span><span class="w"> </span><span class="l">In</span><span class="w">
</span><span class="w">                  </span><span class="nt">values</span><span class="p">:</span><span class="w">
</span><span class="w">                  </span>- <span class="l">xxx</span><span class="w">
</span><span class="w">                </span>- <span class="nt">key</span><span class="p">:</span><span class="w"> </span><span class="l">version</span><span class="w">
</span><span class="w">                  </span><span class="nt">operator</span><span class="p">:</span><span class="w"> </span><span class="l">In</span><span class="w">
</span><span class="w">                  </span><span class="nt">values</span><span class="p">:</span><span class="w">
</span><span class="w">                  </span>- <span class="l">v12</span><span class="w">
</span><span class="w">              </span><span class="c"># 将 pod 尽量打散在多个可用区</span><span class="w">
</span><span class="w">              </span><span class="nt">topologyKey</span><span class="p">:</span><span class="w"> </span><span class="l">topology.kubernetes.io/zone</span><span class="w">
</span><span class="w">          </span><span class="nt">requiredDuringSchedulingIgnoredDuringExecution</span><span class="p">:</span><span class="w">  </span><span class="c"># 强制性要求</span><span class="w">
</span><span class="w">          </span><span class="c"># 注意这个没有 weights，必须满足列表中的所有条件</span><span class="w">
</span><span class="w">          </span>- <span class="nt">labelSelector</span><span class="p">:</span><span class="w">
</span><span class="w">              </span><span class="nt">matchExpressions</span><span class="p">:</span><span class="w">
</span><span class="w">              </span>- <span class="nt">key</span><span class="p">:</span><span class="w"> </span><span class="l">app</span><span class="w">
</span><span class="w">                </span><span class="nt">operator</span><span class="p">:</span><span class="w"> </span><span class="l">In</span><span class="w">
</span><span class="w">                </span><span class="nt">values</span><span class="p">:</span><span class="w">
</span><span class="w">                </span>- <span class="l">xxx</span><span class="w">
</span><span class="w">              </span>- <span class="nt">key</span><span class="p">:</span><span class="w"> </span><span class="l">version</span><span class="w">
</span><span class="w">                </span><span class="nt">operator</span><span class="p">:</span><span class="w"> </span><span class="l">In</span><span class="w">
</span><span class="w">                </span><span class="nt">values</span><span class="p">:</span><span class="w">
</span><span class="w">                </span>- <span class="l">v12</span><span class="w">
</span><span class="w">            </span><span class="c"># Pod 必须运行在不同的节点上</span><span class="w">
</span><span class="w">            </span><span class="nt">topologyKey</span><span class="p">:</span><span class="w"> </span><span class="l">kubernetes.io/hostname</span><span class="w">
</span></code></pre></td></tr></table>
</div>
</div><h2 id="五pod-的就绪探针存活探针与启动探针">五、Pod 的就绪探针、存活探针与启动探针</h2>
<p>Pod 提供如下三种探针，均支持使用 Command、HTTP API、TCP Socket 这三种手段来进行服务可用性探测。</p>
<ul>
<li><code>startupProbe</code> 启动探针（Kubernetes v1.18 [beta]）: 此探针通过后，「就绪探针」与「存活探针」才会进行存活性与就绪检查
<ul>
<li>用于对慢启动容器进行存活性检测，避免它们在启动运行之前就被杀掉
<ul>
<li>startupProbe 显然比 livenessProbe 的 initialDelaySeconds 参数更灵活。</li>
<li>同时它也能延迟 readinessProbe 的生效时间，这主要是为了避免无意义的探测。容器都还没 startUp，显然是不可能就绪的。</li>
</ul>
</li>
<li>程序将最多有 <code>failureThreshold * periodSeconds</code> 的时间用于启动，比如设置 <code>failureThreshold=20</code>、<code>periodSeconds=5</code>，程序启动时间最长就为 100s，如果超过 100s 仍然未通过「启动探测」，容器会被杀死。</li>
</ul>
</li>
<li><code>readinessProbe</code> 就绪探针:
<ul>
<li>就绪探针失败次数超过 <code>failureThreshold</code> 限制（默认三次），服务将被暂时从 Service 的 Endpoints 中踢出，直到服务再次满足 <code>successThreshold</code>.</li>
</ul>
</li>
<li><code>livenessProbe</code> 存活探针: 检测服务是否存活，它可以捕捉到死锁等情况，及时杀死这种容器。
<ul>
<li>存活探针失败可能的原因：
<ul>
<li>服务发生死锁，对所有请求均无响应</li>
<li>服务线程全部卡在对外部 redis/mysql 等外部依赖的等待中，导致请求无响应</li>
</ul>
</li>
<li>存活探针失败次数超过 <code>failureThreshold</code> 限制（默认三次），容器将被杀死，随后根据重启策略执行重启。
<ul>
<li><code>kubectl describe pod</code> 会显示重启原因为 <code>State.Last State.Reason = Error, Exit Code=137</code>，同时 Events 中会有 <code>Liveness probe failed: ...</code> 这样的描述。</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>上述三类探测器的参数都是通用的，五个时间相关的参数列举如下：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-yaml" data-lang="yaml"><span class="c"># 下面的值就是 k8s 的默认值</span><span class="w">
</span><span class="w"></span><span class="nt">initialDelaySeconds</span><span class="p">:</span><span class="w"> </span><span class="m">0</span><span class="w">  </span><span class="c"># 默认没有 delay 时间</span><span class="w">
</span><span class="w"></span><span class="nt">periodSeconds</span><span class="p">:</span><span class="w"> </span><span class="m">10</span><span class="w">
</span><span class="w"></span><span class="nt">timeoutSeconds</span><span class="p">:</span><span class="w"> </span><span class="m">1</span><span class="w">
</span><span class="w"></span><span class="nt">failureThreshold</span><span class="p">:</span><span class="w"> </span><span class="m">3</span><span class="w">
</span><span class="w"></span><span class="nt">successThreshold</span><span class="p">:</span><span class="w"> </span><span class="m">1</span><span class="w">
</span></code></pre></td></tr></table>
</div>
</div><p>示例：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span><span class="lnt">38
</span><span class="lnt">39
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-yaml" data-lang="yaml"><span class="nt">apiVersion</span><span class="p">:</span><span class="w"> </span><span class="l">apps/v1</span><span class="w">
</span><span class="w"></span><span class="nt">kind</span><span class="p">:</span><span class="w"> </span><span class="l">Deployment</span><span class="w">
</span><span class="w"></span><span class="nt">metadata</span><span class="p">:</span><span class="w">
</span><span class="w">  </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">my-app-v3</span><span class="w">
</span><span class="w"></span><span class="nt">spec</span><span class="p">:</span><span class="w">
</span><span class="w">  </span><span class="c"># ...</span><span class="w">
</span><span class="w">  </span><span class="nt">template</span><span class="p">:</span><span class="w">
</span><span class="w">    </span><span class="c">#  ...</span><span class="w">
</span><span class="w">    </span><span class="nt">spec</span><span class="p">:</span><span class="w">
</span><span class="w">      </span><span class="nt">containers</span><span class="p">:</span><span class="w">
</span><span class="w">      </span>- <span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">my-app-v3</span><span class="w">
</span><span class="w">        </span><span class="nt">image</span><span class="p">:</span><span class="w"> </span><span class="l">xxx.com/app/my-app:v3</span><span class="w">
</span><span class="w">        </span><span class="nt">imagePullPolicy</span><span class="p">:</span><span class="w"> </span><span class="l">IfNotPresent </span><span class="w">
</span><span class="w">        </span><span class="c"># ... 省略若干配置</span><span class="w">
</span><span class="w">        </span><span class="nt">startupProbe</span><span class="p">:</span><span class="w">
</span><span class="w">          </span><span class="nt">httpGet</span><span class="p">:</span><span class="w">
</span><span class="w">            </span><span class="nt">path</span><span class="p">:</span><span class="w"> </span><span class="l">/actuator/health </span><span class="w"> </span><span class="c"># 直接使用健康检查接口即可</span><span class="w">
</span><span class="w">            </span><span class="nt">port</span><span class="p">:</span><span class="w"> </span><span class="m">8080</span><span class="w">
</span><span class="w">          </span><span class="nt">periodSeconds</span><span class="p">:</span><span class="w"> </span><span class="m">5</span><span class="w">
</span><span class="w">          </span><span class="nt">timeoutSeconds</span><span class="p">:</span><span class="w"> </span><span class="m">1</span><span class="w">
</span><span class="w">          </span><span class="nt">failureThreshold</span><span class="p">:</span><span class="w"> </span><span class="m">20</span><span class="w">  </span><span class="c"># 最多提供给服务 5s * 20 的启动时间</span><span class="w">
</span><span class="w">          </span><span class="nt">successThreshold</span><span class="p">:</span><span class="w"> </span><span class="m">1</span><span class="w">
</span><span class="w">        </span><span class="nt">livenessProbe</span><span class="p">:</span><span class="w">
</span><span class="w">          </span><span class="nt">httpGet</span><span class="p">:</span><span class="w">
</span><span class="w">            </span><span class="nt">path</span><span class="p">:</span><span class="w"> </span><span class="l">/actuator/health </span><span class="w"> </span><span class="c"># spring 的通用健康检查路径</span><span class="w">
</span><span class="w">            </span><span class="nt">port</span><span class="p">:</span><span class="w"> </span><span class="m">8080</span><span class="w">
</span><span class="w">          </span><span class="nt">periodSeconds</span><span class="p">:</span><span class="w"> </span><span class="m">5</span><span class="w">
</span><span class="w">          </span><span class="nt">timeoutSeconds</span><span class="p">:</span><span class="w"> </span><span class="m">1</span><span class="w">
</span><span class="w">          </span><span class="nt">failureThreshold</span><span class="p">:</span><span class="w"> </span><span class="m">5</span><span class="w">
</span><span class="w">          </span><span class="nt">successThreshold</span><span class="p">:</span><span class="w"> </span><span class="m">1</span><span class="w">
</span><span class="w">        </span><span class="c"># Readiness probes are very important for a RollingUpdate to work properly,</span><span class="w">
</span><span class="w">        </span><span class="nt">readinessProbe</span><span class="p">:</span><span class="w">
</span><span class="w">          </span><span class="nt">httpGet</span><span class="p">:</span><span class="w">
</span><span class="w">            </span><span class="nt">path</span><span class="p">:</span><span class="w"> </span><span class="l">/actuator/health </span><span class="w"> </span><span class="c"># 简单起见可直接使用 livenessProbe 相同的接口，当然也可额外定义</span><span class="w">
</span><span class="w">            </span><span class="nt">port</span><span class="p">:</span><span class="w"> </span><span class="m">8080</span><span class="w">
</span><span class="w">          </span><span class="nt">periodSeconds</span><span class="p">:</span><span class="w"> </span><span class="m">5</span><span class="w">
</span><span class="w">          </span><span class="nt">timeoutSeconds</span><span class="p">:</span><span class="w"> </span><span class="m">1</span><span class="w">
</span><span class="w">          </span><span class="nt">failureThreshold</span><span class="p">:</span><span class="w"> </span><span class="m">5</span><span class="w">
</span><span class="w">          </span><span class="nt">successThreshold</span><span class="p">:</span><span class="w"> </span><span class="m">1</span><span class="w">
</span></code></pre></td></tr></table>
</div>
</div><p>在 Kubernetes 1.18 之前，通用的手段是为「就绪探针」添加较长的 <code>initialDelaySeconds</code> 来实现类似「启动探针」的功能动，避免容器因为启动太慢，存活探针失败导致容器被重启。示例如下：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-yaml" data-lang="yaml"><span class="nt">apiVersion</span><span class="p">:</span><span class="w"> </span><span class="l">apps/v1</span><span class="w">
</span><span class="w"></span><span class="nt">kind</span><span class="p">:</span><span class="w"> </span><span class="l">Deployment</span><span class="w">
</span><span class="w"></span><span class="nt">metadata</span><span class="p">:</span><span class="w">
</span><span class="w">  </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">my-app-v3</span><span class="w">
</span><span class="w"></span><span class="nt">spec</span><span class="p">:</span><span class="w">
</span><span class="w">  </span><span class="c"># ...</span><span class="w">
</span><span class="w">  </span><span class="nt">template</span><span class="p">:</span><span class="w">
</span><span class="w">    </span><span class="c">#  ...</span><span class="w">
</span><span class="w">    </span><span class="nt">spec</span><span class="p">:</span><span class="w">
</span><span class="w">      </span><span class="nt">containers</span><span class="p">:</span><span class="w">
</span><span class="w">      </span>- <span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">my-app-v3</span><span class="w">
</span><span class="w">        </span><span class="nt">image</span><span class="p">:</span><span class="w"> </span><span class="l">xxx.com/app/my-app:v3</span><span class="w">
</span><span class="w">        </span><span class="nt">imagePullPolicy</span><span class="p">:</span><span class="w"> </span><span class="l">IfNotPresent </span><span class="w">
</span><span class="w">        </span><span class="c"># ... 省略若干配置</span><span class="w">
</span><span class="w">        </span><span class="nt">livenessProbe</span><span class="p">:</span><span class="w">
</span><span class="w">          </span><span class="nt">httpGet</span><span class="p">:</span><span class="w">
</span><span class="w">            </span><span class="nt">path</span><span class="p">:</span><span class="w"> </span><span class="l">/actuator/health </span><span class="w"> </span><span class="c"># spring 的通用健康检查路径</span><span class="w">
</span><span class="w">            </span><span class="nt">port</span><span class="p">:</span><span class="w"> </span><span class="m">8080</span><span class="w">
</span><span class="w">          </span><span class="nt">initialDelaySeconds</span><span class="p">:</span><span class="w"> </span><span class="m">120</span><span class="w">  </span><span class="c"># 前两分钟，都假设服务健康，避免 livenessProbe 失败导致服务重启</span><span class="w">
</span><span class="w">          </span><span class="nt">periodSeconds</span><span class="p">:</span><span class="w"> </span><span class="m">5</span><span class="w">
</span><span class="w">          </span><span class="nt">timeoutSeconds</span><span class="p">:</span><span class="w"> </span><span class="m">1</span><span class="w">
</span><span class="w">          </span><span class="nt">failureThreshold</span><span class="p">:</span><span class="w"> </span><span class="m">5</span><span class="w">
</span><span class="w">          </span><span class="nt">successThreshold</span><span class="p">:</span><span class="w"> </span><span class="m">1</span><span class="w">
</span><span class="w">        </span><span class="c"># 容器一启动，Readiness probes 就会不断进行检测</span><span class="w">
</span><span class="w">        </span><span class="nt">readinessProbe</span><span class="p">:</span><span class="w">
</span><span class="w">          </span><span class="nt">httpGet</span><span class="p">:</span><span class="w">
</span><span class="w">            </span><span class="nt">path</span><span class="p">:</span><span class="w"> </span><span class="l">/actuator/health</span><span class="w">
</span><span class="w">            </span><span class="nt">port</span><span class="p">:</span><span class="w"> </span><span class="m">8080</span><span class="w">
</span><span class="w">          </span><span class="nt">initialDelaySeconds</span><span class="p">:</span><span class="w"> </span><span class="m">3</span><span class="w">  </span><span class="c"># readiness probe 不需要设太长时间，使 Pod 尽快加入到 Endpoints.</span><span class="w">
</span><span class="w">          </span><span class="nt">periodSeconds</span><span class="p">:</span><span class="w"> </span><span class="m">5</span><span class="w">
</span><span class="w">          </span><span class="nt">timeoutSeconds</span><span class="p">:</span><span class="w"> </span><span class="m">1</span><span class="w">
</span><span class="w">          </span><span class="nt">failureThreshold</span><span class="p">:</span><span class="w"> </span><span class="m">5</span><span class="w">
</span><span class="w">          </span><span class="nt">successThreshold</span><span class="p">:</span><span class="w"> </span><span class="m">1</span><span class="w">
</span></code></pre></td></tr></table>
</div>
</div><h2 id="security">六、Pod 安全</h2>
<p>这里只介绍 Pod 中安全相关的参数，其他诸如集群全局的安全策略，不在这里讨论。</p>
<h3 id="1-pod-securitycontexthttpskubernetesiodocstasksconfigure-pod-containersecurity-context">1. <a href="https://kubernetes.io/docs/tasks/configure-pod-container/security-context/" target="_blank" rel="noopener noreferrer">Pod SecurityContext</a></h3>
<p>通过设置 Pod 的 SecurityContext，可以为每个 Pod 设置特定的安全策略。</p>
<p>SecurityContext 有两种类型：</p>
<ol>
<li><code>spec.securityContext</code>: 这是一个 <a href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.20/#podsecuritycontext-v1-core" target="_blank" rel="noopener noreferrer">PodSecurityContext</a> 对象
<ul>
<li>顾名思义，它对 Pod 中的所有 contaienrs 都有效。</li>
</ul>
</li>
<li><code>spec.containers[*].securityContext</code>: 这是一个 <a href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.20/#securitycontext-v1-core" target="_blank" rel="noopener noreferrer">SecurityContext</a> 对象
<ul>
<li>container 私有的 SecurityContext</li>
</ul>
</li>
</ol>
<p>这两个 SecurityContext 的参数只有部分重叠，重叠的部分 <code>spec.containers[*].securityContext</code> 优先级更高。</p>
<p>我们比较常遇到的一些<strong>提升权限</strong>的安全策略：</p>
<ol>
<li>特权容器：<code>spec.containers[*].securityContext.privileged</code></li>
<li>添加（Capabilities）可选的系统级能力: <code>spec.containers[*].securityContext.capabilities.add</code>
<ol>
<li>只有 ntp 同步服务等少数容器，可以开启这项功能。请注意这非常危险。</li>
</ol>
</li>
<li>Sysctls: 系统参数: <code>spec.securityContext.sysctls</code></li>
</ol>
<p><strong>权限限制</strong>相关的安全策略有（<strong>强烈建议在所有 Pod 上按需配置如下安全策略！</strong>）：</p>
<ol>
<li><code>spec.volumes</code>: 所有的数据卷都可以设定读写权限</li>
<li><code>spec.securityContext.runAsNonRoot: true</code> Pod 必须以非 root 用户运行</li>
<li><code>spec.containers[*].securityContext.readOnlyRootFileSystem:true</code> <strong>将容器层设为只读，防止容器文件被篡改。</strong>
<ol>
<li>如果微服务需要读写文件，建议额外挂载 <code>emptydir</code> 类型的数据卷。</li>
</ol>
</li>
<li><code>spec.containers[*].securityContext.allowPrivilegeEscalation: false</code> 不允许 Pod 做任何权限提升！</li>
<li><code>spec.containers[*].securityContext.capabilities.drop</code>: 移除（Capabilities）可选的系统级能力</li>
</ol>
<p>还有其他诸如指定容器的运行用户(user)/用户组(group)等功能未列出，请自行查阅 Kubernetes 相关文档。</p>
<p>一个无状态的微服务 Pod 配置举例：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-yaml" data-lang="yaml"><span class="nt">apiVersion</span><span class="p">:</span><span class="w"> </span><span class="l">v1</span><span class="w">
</span><span class="w"></span><span class="nt">kind</span><span class="p">:</span><span class="w"> </span><span class="l">Pod</span><span class="w">
</span><span class="w"></span><span class="nt">metadata</span><span class="p">:</span><span class="w">
</span><span class="w">  </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">&lt;Pod name&gt;</span><span class="w">
</span><span class="w"></span><span class="nt">spec</span><span class="p">:</span><span class="w">
</span><span class="w">  </span><span class="nt">containers</span><span class="p">:</span><span class="w">
</span><span class="w">  </span><span class="nt">- name</span><span class="p">:</span><span class="w"> </span><span class="l">&lt;container name&gt;</span><span class="w">
</span><span class="w">    </span><span class="nt">image</span><span class="p">:</span><span class="w"> </span><span class="l">&lt;image&gt;</span><span class="w">
</span><span class="w">    </span><span class="nt">imagePullPolicy</span><span class="p">:</span><span class="w"> </span><span class="l">IfNotPresent </span><span class="w">
</span><span class="w">    </span><span class="c"># ......此处省略 500 字</span><span class="w">
</span><span class="w">    </span><span class="nt">securityContext</span><span class="p">:</span><span class="w">
</span><span class="w">      </span><span class="nt">readOnlyRootFilesystem</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span><span class="w">  </span><span class="c"># 将容器层设为只读，防止容器文件被篡改。</span><span class="w">
</span><span class="w">      </span><span class="nt">allowPrivilegeEscalation</span><span class="p">:</span><span class="w"> </span><span class="kc">false</span><span class="w">  </span><span class="c"># 禁止 Pod 做任何权限提升</span><span class="w">
</span><span class="w">      </span><span class="nt">capabilities</span><span class="p">:</span><span class="w">
</span><span class="w">        </span><span class="nt">drop</span><span class="p">:</span><span class="w">
</span><span class="w">        </span><span class="c"># 禁止容器使用 raw 套接字，通常只有 hacker 才会用到 raw 套接字。</span><span class="w">
</span><span class="w">        </span><span class="c"># raw_socket 可自定义网络层数据，避开 tcp/udp 协议栈，直接操作底层的 ip/icmp 数据包。可实现 ip 伪装、自定义协议等功能。</span><span class="w">
</span><span class="w">        </span><span class="c"># 去掉 net_raw 会导致 tcpdump 无法使用，无法进行容器内抓包。需要抓包时可临时去除这项配置</span><span class="w">
</span><span class="w">        </span>- <span class="l">NET_RAW</span><span class="w">
</span><span class="w">        </span><span class="c"># 更好的选择：直接禁用所有 capabilities</span><span class="w">
</span><span class="w">        </span><span class="c"># - ALL</span><span class="w">
</span><span class="w">  </span><span class="nt">securityContext</span><span class="p">:</span><span class="w">
</span><span class="w">    </span><span class="c"># runAsUser: 1000  # 设定用户</span><span class="w">
</span><span class="w">    </span><span class="c"># runAsGroup: 1000  # 设定用户组</span><span class="w">
</span><span class="w">    </span><span class="nt">runAsNonRoot</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span><span class="w">  </span><span class="c"># Pod 必须以非 root 用户运行</span><span class="w">
</span><span class="w">    </span><span class="nt">seccompProfile</span><span class="p">:</span><span class="w">  </span><span class="c"># security compute mode</span><span class="w">
</span><span class="w">      </span><span class="nt">type</span><span class="p">:</span><span class="w"> </span><span class="l">RuntimeDefault</span><span class="w">
</span></code></pre></td></tr></table>
</div>
</div><h3 id="2-seccomp-security-compute-mode">2. seccomp: security compute mode</h3>
<p>seccomp 和 seccomp-bpf 允许对系统调用进行过滤，可以防止用户的二进制文对主机操作系统件执行通常情况下并不需要的危险操作。它和 Falco 有些类似，不过 Seccomp 没有为容器提供特别的支持。</p>
<p>视频:</p>
<ul>
<li><a href="https://www.youtube.com/watch?v=Ro4QRx7VPsY&amp;list=PLj6h78yzYM2Pn8RxfLh2qrXBDftr6Qjut$index=22" target="_blank" rel="noopener noreferrer">Seccomp: What Can It Do For You? - Justin Cormack, Docker</a></li>
</ul>
<h2 id="其他问题">其他问题</h2>
<ul>
<li>不同节点类型的性能有差距，导致 QPS 均衡的情况下，CPU 负载不均衡
<ul>
<li>解决办法（未验证）：
<ul>
<li>尽量使用性能相同的实例类型：通过 <code>podAffinity</code> 及 <code>nodeAffinity</code> 添加节点类型的亲和性</li>
</ul>
</li>
</ul>
</li>
</ul>
]]></description></item><item><title>使用 Istio 进行 JWT 身份验证（充当 API 网关）</title><link>https://ryan4yin.space/posts/use-istio-for-jwt-auth/</link><pubDate>Mon, 06 Apr 2020 21:48:26 +0800</pubDate><author>xiaoyin_c@qq.com</author><dc:creator>ryan4yin</dc:creator><guid>https://ryan4yin.space/posts/use-istio-for-jwt-auth/</guid><description><![CDATA[<blockquote>
<p>本文基于 Istio1.5 编写测试</p>
</blockquote>
<p>Istio 支持使用 JWT 对终端用户进行身份验证（Istio End User Authentication），支持多种 JWT 签名算法。</p>
<p>目前主流的 JWT 算法是 RS256/ES256。（请忽略 HS256，该算法不适合分布式 JWT 验证）</p>
<p>这里以 RSA256 算法为例进行介绍，ES256 的配置方式也是一样的。</p>
<h3 id="1-介绍-jwk-与-jwks">1. 介绍 JWK 与 JWKS</h3>
<p>Istio 要求提供 JWKS 格式的信息，用于 JWT 签名验证。因此这里得先介绍一下 JWK 和 JWKS.</p>
<p>JWKS ，也就是 JWK Set，json 结构如下：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-fallback" data-lang="fallback">{
&#34;keys&#34;: [
  &lt;jwk-1&gt;,
  &lt;jwk-2&gt;,
  ...
]}
</code></pre></td></tr></table>
</div>
</div><p>JWKS 描述一组 JWK 密钥。它能同时描述多个可用的公钥，应用场景之一是密钥的 Rotate.</p>
<p>而 JWK，全称是 Json Web Key，它描述了一个加密密钥（公钥或私钥）的各项属性，包括密钥的值。</p>
<p>Istio 使用 JWK 描述验证 JWT 签名所需要的信息。在使用 RSA 签名算法时，JWK 描述的应该是用于验证的 RSA 公钥。</p>
<p>一个 RSA 公钥的 JWK 描述如下：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span><span class="lnt">8
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-fallback" data-lang="fallback">{
    &#34;alg&#34;: &#34;RS256&#34;,  # 算法「可选参数」
    &#34;kty&#34;: &#34;RSA&#34;,    # 密钥类型
    &#34;use&#34;: &#34;sig&#34;,    # 被用于签名「可选参数」
    &#34;kid&#34;: &#34;NjVBRjY5MDlCMUIwNzU4RTA2QzZFMDQ4QzQ2MDAyQjVDNjk1RTM2Qg&#34;,  # key 的唯一 id
    &#34;n&#34;: &#34;yeNlzlub94YgerT030codqEztjfU_S6X4DbDA_iVKkjAWtYfPHDzz_sPCT1Axz6isZdf3lHpq_gYX4Sz-cbe4rjmigxUxr-FgKHQy3HeCdK6hNq9ASQvMK9LBOpXDNn7mei6RZWom4wo3CMvvsY1w8tjtfLb-yQwJPltHxShZq5-ihC9irpLI9xEBTgG12q5lGIFPhTl_7inA1PFK97LuSLnTJzW0bj096v_TMDg7pOWm_zHtF53qbVsI0e3v5nmdKXdFf9BjIARRfVrbxVxiZHjU6zL6jY5QJdh1QCmENoejj_ytspMmGW7yMRxzUqgxcAqOBpVm0b-_mW3HoBdjQ&#34;,
    &#34;e&#34;: &#34;AQAB&#34;
}
</code></pre></td></tr></table>
</div>
</div><p>RSA 是基于大数分解的加密/签名算法，上述参数中，<code>e</code> 是公钥的模数(modulus)，<code>n</code> 是公钥的指数(exponent)，两个参数都是 base64 字符串。</p>
<p>JWK 中 RSA 公钥的具体定义参见 <a href="https://tools.ietf.org/html/rfc7518#page-30" target="_blank" rel="noopener noreferrer">RSA Keys - JSON Web Algorithms (JWA)</a></p>
<h3 id="2-jwk-的生成">2. JWK 的生成</h3>
<p>要生成 JWK 公钥，需要先生成私钥，生成方法参见 <a href="/posts/jwt-algorithm-key-generation/#使用-openssl-生成-rsaecc-公私钥" rel="">JWT 签名算法 HS256、RS256 及 ES256 及密钥生成</a>。</p>
<blockquote>
<p>公钥不需要用上述方法生成，因为我们需要的是 JWK 格式的公钥。后面会通过 python 生成出 JWK 公钥。</p>
</blockquote>
<p>上面的命令会将生成出的 RSA 私钥写入 key.pem 中，查看一下私钥内容。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-fallback" data-lang="fallback">ryan@RYAN-MI-DESKTOP:~/istio$ cat key.pem
-----BEGIN RSA PRIVATE KEY-----
MIIEpAIBAAKCAQEAt1cKkQqPh8iOv5BhKh7Rx6A2+1ldpO/jczML/0GBKu4X+lHr
Y8YbJrt29jyAXlWM8vHC7tXsqgUG+WziRD0D8nhnh10XC14SeH+3mVuBqph+TqhX
TWsh9gtAIbeUHJjEI4I79QK4/wquPHHIGZBQDQQnuMh6vAS3VaUYJdEIoKvUBnAy
Y35kJZgyJSbrxLsEExL2zujUD/OY+/In2bq/3rFtDGNlgHyC7Gu2zXSXvfOA4O5m
9BBXOc7eEqj7PoOKNaTxLN3YcuRtgR6NIXL4KLb6oyvIzoeiprt4+9q7sc3Dnkc5
EV9kwWlEW2DHzhP6VYca0WXIIXc53U1AM3ewxwIDAQABAoIBABIKhaaqJF+XM7zU
B0uuxrPfJynqrFVbqcUfQ9H1bzF7Rm7CeuhRiUBxeA5Y+8TMpFcPxT/dWzGL1xja
RxWx715/zKg8V9Uth6HF55o2r/bKlLtGw3iBz1C34LKwrul1eu+HlEDS6MNoGKco
BynE0qvFOedsCu/Pgv7xhQPLow60Ty1uM0AhbcPgi6yJ5ksRB1XjtEnW0t+c8yQS
nU3mU8k230SdMhf4Ifud/5TPLjmXdFpyPi9uYiVdJ5oWsmMWEvekXoBnHWDDF/eT
VkVMiTBorT4qn+Ax1VjHL2VOMO5ZbXEcpbIc3Uer7eZAaDQ0NPZK37IkIn9TiZ21
cqzgbCkCgYEA5enHZbD5JgfwSNWCaiNrcBhYjpCtvfbT82yGW+J4/Qe/H+bY/hmJ
RRTKf0kVPdRwZzq7GphVMWIuezbOk0aFGhk/SzIveW8QpLY0FV/5xFnGNjV9AuNc
xrmgVshUsyQvr1TFkbdkC6yuvNgQfXfnbEoaPsXYEMCii2zqdF5lWGUCgYEAzCR2
6g8vEQx0hdRS5d0zD2/9IRYNzfP5oK0+F3KHH2OuwlmQVIo7IhCiUgqserXNBDef
hj+GNcU8O/yXLomAXG7VG/cLWRrpY8d9bcRMrwb0/SkNr0yNrkqHiWQ/PvR+2MLk
viWFZTTp8YizPA+8pSC/oFd1jkZF0UhKVAREM7sCgYB5+mfxyczFopyW58ADM7uC
g0goixXCnTuiAEfgY+0wwXVjJYSme0HaxscQdOOyJA1ml0BBQeShCKgEcvVyKY3g
ZNixunR5hrVbzdcgKAVJaR/CDuq+J4ZHYKByqmJVkLND4EPZpWSM1Rb31eIZzw2W
5FG8UBbr/GfAdQ6GorY+CQKBgQCzWQHkBmz6VG/2t6AQ9LIMSP4hWEfOfh78q9dW
MDdIO4JomtkzfLIQ7n49B8WalShGITwUbLDTgrG1neeQahsMmg6+X99nbD5JfBTV
H9WjG8CWvb+ZF++NhUroSNtLyu+6LhdaeopkbQVvPwMArG62wDu6ebv8v/5MrG8o
uwrUSwKBgQCxV43ZqTRnEuDlF7jMN+2JZWhpbrucTG5INoMPOC0ZVatePszZjYm8
LrmqQZHer2nqtFpyslwgKMWgmVLJTH7sVf0hS9po0+iSYY/r8e/c85UdUreb0xyT
x8whrOnMMODCAqu4W/Rx1Lgf2vXIx0pZmlt8Df9i2AVg/ePR6jO3Nw==
-----END RSA PRIVATE KEY-----
</code></pre></td></tr></table>
</div>
</div><p>接下来通过 Python 编程生成 RSA Public Key 和 JWK（jwk 其实就是公钥的另一个表述形式而已）:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-fallback" data-lang="fallback"># 需要先安装依赖: pip install jwcrypto
from jwcrypto.jwk import JWK
from pathlib import Path

private_key = Path(&#34;key.pem&#34;).read_bytes()
jwk = JWK.from_pem(private_key)

# 导出公钥 RSA Public Key
public_key = jwk.public().export_to_pem()
print(public_key)

print(&#34;=&#34;*30)

# 导出 JWK
jwk_bytes = jwk.public().export()
print(jwk_bytes)
</code></pre></td></tr></table>
</div>
</div><p>Istio 需要 JWK 进行 JWT 验证，而我们手动验证 JWT 时一般需要用到 Public Key. 方便起见，上述代码把这两个都打印了出来。内容如下：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-fallback" data-lang="fallback"># Public Key 内容，不包含这行注释
-----BEGIN PUBLIC KEY-----
MIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAt1cKkQqPh8iOv5BhKh7R
x6A2+1ldpO/jczML/0GBKu4X+lHrY8YbJrt29jyAXlWM8vHC7tXsqgUG+WziRD0D
8nhnh10XC14SeH+3mVuBqph+TqhXTWsh9gtAIbeUHJjEI4I79QK4/wquPHHIGZBQ
DQQnuMh6vAS3VaUYJdEIoKvUBnAyY35kJZgyJSbrxLsEExL2zujUD/OY+/In2bq/
3rFtDGNlgHyC7Gu2zXSXvfOA4O5m9BBXOc7eEqj7PoOKNaTxLN3YcuRtgR6NIXL4
KLb6oyvIzoeiprt4+9q7sc3Dnkc5EV9kwWlEW2DHzhP6VYca0WXIIXc53U1AM3ew
xwIDAQAB
-----END PUBLIC KEY-----
</code></pre></td></tr></table>
</div>
</div><div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-fallback" data-lang="fallback"># jwk 内容
{
 &#39;e&#39;: &#39;AQAB&#39;,
 &#39;kid&#39;: &#39;oyYwZSLCLVVPHdVp0jXIcLNpGn6dMCumlY-6wSenmFo&#39;,
 &#39;kty&#39;: &#39;RSA&#39;,
 &#39;n&#39;: &#39;t1cKkQqPh8iOv5BhKh7Rx6A2-1ldpO_jczML_0GBKu4X-lHrY8YbJrt29jyAXlWM8vHC7tXsqgUG-WziRD0D8nhnh10XC14SeH-3mVuBqph-TqhXTWsh9gtAIbeUHJjEI4I79QK4_wquPHHIGZBQDQQnuMh6vAS3VaUYJdEIoKvUBnAyY35kJZgyJSbrxLsEExL2zujUD_OY-_In2bq_3rFtDGNlgHyC7Gu2zXSXvfOA4O5m9BBXOc7eEqj7PoOKNaTxLN3YcuRtgR6NIXL4KLb6oyvIzoeiprt4-9q7sc3Dnkc5EV9kwWlEW2DHzhP6VYca0WXIIXc53U1AM3ewxw&#39;
}
</code></pre></td></tr></table>
</div>
</div><h3 id="4-测试密钥可用性">4. 测试密钥可用性</h3>
<p>接下来在 <a href="https://jwt.io" target="_blank" rel="noopener noreferrer">jwt.io</a> 中填入测试用的公钥私钥，还有 Header/Payload。一是测试公私钥的可用性，二是生成出 JWT 供后续测试 Istio JWT 验证功能的可用性。
</p>
<p>可以看到左下角显示「Signature Verified」，成功地生成出了 JWT。后续可以使用这个 JWT 访问 Istio 网关，测试 Istio JWT 验证功能。</p>
<h3 id="5-启用-istio-的身份验证">5. 启用 Istio 的身份验证</h3>
<p>编写 istio 配置：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-yaml" data-lang="yaml"><span class="nt">apiVersion</span><span class="p">:</span><span class="w"> </span><span class="s2">&#34;security.istio.io/v1beta1&#34;</span><span class="w">
</span><span class="w"></span><span class="nt">kind</span><span class="p">:</span><span class="w"> </span><span class="s2">&#34;RequestAuthentication&#34;</span><span class="w">
</span><span class="w"></span><span class="nt">metadata</span><span class="p">:</span><span class="w">
</span><span class="w">  </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="s2">&#34;jwt-example&#34;</span><span class="w">
</span><span class="w">  </span><span class="nt">namespace</span><span class="p">:</span><span class="w"> </span><span class="l">istio-system </span><span class="w"> </span><span class="c"># istio-system 名字空间中的配置，默认情况下会应用到所有名字空间</span><span class="w">
</span><span class="w"></span><span class="nt">spec</span><span class="p">:</span><span class="w">
</span><span class="w">  </span><span class="nt">selector</span><span class="p">:</span><span class="w">
</span><span class="w">    </span><span class="nt">matchLabels</span><span class="p">:</span><span class="w">
</span><span class="w">      </span><span class="nt">istio</span><span class="p">:</span><span class="w"> </span><span class="l">ingressgateway</span><span class="w">
</span><span class="w">  </span><span class="nt">jwtRules</span><span class="p">:</span><span class="w">
</span><span class="w">  </span><span class="c"># issuer 即签发者，需要和 JWT payload 中的 iss 属性完全一致。</span><span class="w">
</span><span class="w">  </span>- <span class="nt">issuer</span><span class="p">:</span><span class="w"> </span><span class="s2">&#34;testing@secure.istio.io&#34;</span><span class="w">
</span><span class="w">    </span><span class="nt">jwks</span><span class="p">:</span><span class="w"> </span><span class="p">|</span><span class="sd">
</span><span class="sd">    {
</span><span class="sd">        &#34;keys&#34;: [
</span><span class="sd">            {
</span><span class="sd">                &#34;e&#34;: &#34;AQAB&#34;,
</span><span class="sd">                &#34;kid&#34;: &#34;oyYwZSLCLVVPHdVp0jXIcLNpGn6dMCumlY-6wSenmFo&#34;,  # kid 需要与 jwt header 中的 kid 完全一致。
</span><span class="sd">                &#34;kty&#34;: &#34;RSA&#34;,
</span><span class="sd">                &#34;n&#34;: &#34;t1cKkQqPh8iOv5BhKh7Rx6A2-1ldpO_jczML_0GBKu4X-lHrY8YbJrt29jyAXlWM8vHC7tXsqgUG-WziRD0D8nhnh10XC14SeH-3mVuBqph-TqhXTWsh9gtAIbeUHJjEI4I79QK4_wquPHHIGZBQDQQnuMh6vAS3VaUYJdEIoKvUBnAyY35kJZgyJSbrxLsEExL2zujUD_OY-_In2bq_3rFtDGNlgHyC7Gu2zXSXvfOA4O5m9BBXOc7eEqj7PoOKNaTxLN3YcuRtgR6NIXL4KLb6oyvIzoeiprt4-9q7sc3Dnkc5EV9kwWlEW2DHzhP6VYca0WXIIXc53U1AM3ewxw&#34;
</span><span class="sd">            }
</span><span class="sd">        ]
</span><span class="sd">    }
</span><span class="sd">      # jwks 或 jwksUri 二选其一
</span><span class="sd">      # jwksUri: &#34;http://nginx.test.local/istio/jwks.json&#34;</span><span class="w">    
</span></code></pre></td></tr></table>
</div>
</div><p>现在 <code>kubectl apply</code> 一下，JWT 验证就添加到全局了。</p>
<p>可以看到 jwtRules 是一个列表，因此可以为每个 issuers 配置不同的 jwtRule.</p>
<p>对同一个 issuers（jwt 签发者），可以通过 jwks 设置多个公钥，以实现JWT签名密钥的轮转。
JWT 的验证规则是：</p>
<ol>
<li>JWT 的 payload 中有 issuer 属性，首先通过 issuer 匹配到对应的 istio 中配置的 jwks。</li>
<li>JWT 的 header 中有 kid 属性，第二步在 jwks 的公钥列表中，中找到 kid 相同的公钥。</li>
<li>使用找到的公钥进行 JWT 签名验证。</li>
</ol>
<h3 id="6-启用-payload-转发authorization-转发">6. 启用 Payload 转发/Authorization 转发</h3>
<p>默认情况下，Istio 在完成了身份验证之后，会去掉 Authorization 请求头再进行转发。
这将导致我们的后端服务获取不到对应的 Payload，无法判断 End User 的身份。
因此我们需要启用 Istio 的 Authorization 请求头的转发功能，在前述的 <code>RequestAuthentication</code> yaml 配置中添加一个参数就行：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-yaml" data-lang="yaml"><span class="nt">apiVersion</span><span class="p">:</span><span class="w"> </span><span class="s2">&#34;security.istio.io/v1beta1&#34;</span><span class="w">
</span><span class="w"></span><span class="nt">kind</span><span class="p">:</span><span class="w"> </span><span class="s2">&#34;RequestAuthentication&#34;</span><span class="w">
</span><span class="w"></span><span class="nt">metadata</span><span class="p">:</span><span class="w">
</span><span class="w">  </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="s2">&#34;jwt-example&#34;</span><span class="w">
</span><span class="w">  </span><span class="nt">namespace</span><span class="p">:</span><span class="w"> </span><span class="l">istio-system</span><span class="w">
</span><span class="w"></span><span class="nt">spec</span><span class="p">:</span><span class="w">
</span><span class="w">  </span><span class="nt">selector</span><span class="p">:</span><span class="w">
</span><span class="w">    </span><span class="nt">matchLabels</span><span class="p">:</span><span class="w">
</span><span class="w">      </span><span class="nt">istio</span><span class="p">:</span><span class="w"> </span><span class="l">ingressgateway</span><span class="w">
</span><span class="w">  </span><span class="nt">jwtRules</span><span class="p">:</span><span class="w">
</span><span class="w">  </span>- <span class="nt">issuer</span><span class="p">:</span><span class="w"> </span><span class="s2">&#34;testing@secure.istio.io&#34;</span><span class="w">
</span><span class="w">    </span><span class="nt">jwks</span><span class="p">:</span><span class="w"> </span><span class="p">|</span><span class="sd">
</span><span class="sd">    {
</span><span class="sd">        &#34;keys&#34;: [
</span><span class="sd">            {
</span><span class="sd">                &#34;e&#34;: &#34;AQAB&#34;,
</span><span class="sd">                &#34;kid&#34;: &#34;oyYwZSLCLVVPHdVp0jXIcLNpGn6dMCumlY-6wSenmFo&#34;,
</span><span class="sd">                &#34;kty&#34;: &#34;RSA&#34;,
</span><span class="sd">                &#34;n&#34;: &#34;t1cKkQqPh8iOv5BhKh7Rx6A2-1ldpO_jczML_0GBKu4X-lHrY8YbJrt29jyAXlWM8vHC7tXsqgUG-WziRD0D8nhnh10XC14SeH-3mVuBqph-TqhXTWsh9gtAIbeUHJjEI4I79QK4_wquPHHIGZBQDQQnuMh6vAS3VaUYJdEIoKvUBnAyY35kJZgyJSbrxLsEExL2zujUD_OY-_In2bq_3rFtDGNlgHyC7Gu2zXSXvfOA4O5m9BBXOc7eEqj7PoOKNaTxLN3YcuRtgR6NIXL4KLb6oyvIzoeiprt4-9q7sc3Dnkc5EV9kwWlEW2DHzhP6VYca0WXIIXc53U1AM3ewxw&#34;
</span><span class="sd">            }
</span><span class="sd">        ]
</span><span class="sd">    }</span><span class="w">    
</span><span class="w"></span><span class="c"># ===================== 添加如下参数===========================</span><span class="w">
</span><span class="w">    </span><span class="nt">forwardOriginalToken</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span><span class="w">  </span><span class="c"># 转发 Authorization 请求头</span><span class="w">
</span></code></pre></td></tr></table>
</div>
</div><p>加了转发后，流程图如下（需要 mermaid 渲染）：</p>
<div class="mermaid" id="id-1"></div>
<h2 id="其他问题">其他问题</h2>
<h3 id="1-authorizationpolicy">1. AuthorizationPolicy</h3>
<p>Istio 的 JWT 验证规则，默认情况下会直接忽略不带 Authorization 请求头的流量，因此这类流量能直接进入网格内部。如果需要禁止不带 Authorization 头的流量，需要额外配置 AuthorizationPolicy 策略。</p>
<p>RequestsAuthentication 验证失败的请求，Istio 会返回 401 状态码。
AuthorizationPolicy 验证失败的请求，Istio 会返回 403 状态码。</p>
<p>这会导致在使用 AuthorizationPolicy 禁止了不带 Authorization 头的流量后，这类请求会直接被返回 403。。。在使用 RESTful API 时，这种情况可能会造成一定的问题。</p>
<h3 id="2-response-headers">2. Response Headers</h3>
<p>RequestsAuthentication 不支持自定义响应头信息，这导致对于前后端分离的 Web API 而言，
一旦 JWT 失效，Istio 会直接将 401 返回给前端 Web 页面。
因为响应头中不包含 <code>Access-Crontrol-Allow-Origin</code>，响应将被浏览器拦截！</p>
<p>这可能需要通过 EnvoyFilter 自定义响应头，添加跨域信息。</p>
<h2 id="参考">参考</h2>
<ul>
<li><a href="https://auth0.com/docs/tokens/references/jwks-properties" target="_blank" rel="noopener noreferrer">JSON Web Key Set Properties - Auth0</a></li>
<li><a href="https://tools.ietf.org/html/rfc7517" target="_blank" rel="noopener noreferrer">JWK - RFC7517</a></li>
<li><a href="https://github.com/istio/istio/tree/master/security/tools/jwt/samples" target="_blank" rel="noopener noreferrer">Sample JWT and JWKS data for demo - Istio Security</a></li>
<li><a href="https://istio.io/docs/tasks/security/authentication/authn-policy/#end-user-authentication" target="_blank" rel="noopener noreferrer">End User Authentication - Istio</a></li>
<li><a href="https://istio.io/docs/reference/config/security/jwt/" target="_blank" rel="noopener noreferrer">JWTRule - Istio</a></li>
<li><a href="https://jwt.io/" target="_blank" rel="noopener noreferrer">jwt.io - 动态生成 jwt</a></li>
</ul>]]></description></item><item><title>Kubernetes 常见错误、原因及处理方法</title><link>https://ryan4yin.space/posts/kubernetes-common-errors-and-solutions/</link><pubDate>Sun, 24 Nov 2019 19:26:54 +0800</pubDate><author>xiaoyin_c@qq.com</author><dc:creator>ryan4yin</dc:creator><guid>https://ryan4yin.space/posts/kubernetes-common-errors-and-solutions/</guid><description><![CDATA[<h2 id="pod-常见错误">Pod 常见错误</h2>
<ol>
<li>OOMKilled: Pod 的内存使用超出了 resources.limits 中的限制，被强制杀死。</li>
<li><a href="https://cloud.tencent.com/developer/article/1411527" target="_blank" rel="noopener noreferrer">SandboxChanged: Pod sandbox changed, it will be killed and re-created</a>: 很可能是由于内存限制导致容器被 OOMKilled，或者其他资源不足
<ol>
<li>如果是 OOM，容器通常会被重启，<code>kubectl describe</code> 能看到容器上次被重启的原因 <code>State.Last State.Reason = OOMKilled, Exit Code=137</code>.</li>
</ol>
</li>
<li>Pod 不断被重启，<code>kubectl describe</code> 显示重启原因 <code>State.Last State.Reason = Error, Exit Code=137</code>，137 对应 SIGKILL(<code>kill -9</code>) 信号，说明容器被强制重启。可能的原因：
<ol>
<li>最有可能的原因是，存活探针（livenessProbe）检查失败</li>
<li>节点资源不足，内核强制关闭了进程以释放资源，这种情况可以通过 <code>journalctl -k</code> 查看详细的系统日志。</li>
</ol>
</li>
<li>CrashLoopBackoff: Pod 进入 <strong>崩溃-重启</strong>循环，重启间隔时间从 10 20 40 80 一直翻倍到上限 300 秒，然后以 300 秒为间隔无限重启。</li>
<li>Pod 一直 Pending: 这说明没有任何节点能满足 Pod 的要求，容器无法被调度。比如端口被别的容器用 hostPort 占用，节点有污点等。</li>
<li><a href="" rel="">FailedCreateSandBox: Failed create pod sandbox: rpc error: code = DeadlineExceeded desc = context deadline exceeded</a>：很可能是 CNI 网络插件的问题（比如 ip 地址溢出），</li>
<li><a href="https://github.com/kubernetes/kubernetes/issues/55094" target="_blank" rel="noopener noreferrer">FailedSync: error determining status: rpc error: code = DeadlineExceeded desc = context deadline exceeded</a>: 常和前两个错误先后出现，很可能是 CNI 网络插件的问题。</li>
<li>开发集群，一次性部署所有服务时，各 Pod 互相争抢资源，导致 Pod 生存探针失败，不断重启，重启进一步加重资源使用。恶性循环。
<ul>
<li><strong>需要给每个 Pod 加上 resources.requests，这样资源不足时，后续 Pod 会停止调度，直到资源恢复正常。</strong></li>
</ul>
</li>
<li>Pod 出现大量的 Failed 记录，Deployment 一直重复建立 Pod: 通过 <code>kubectl describe/edit pod &lt;pod-name&gt;</code> 查看 pod <code>Events</code> 和 <code>Status</code>，一般会看到失败信息，如节点异常导致 Pod 被驱逐。</li>
<li><a href="https://zhuanlan.zhihu.com/p/70031676" target="_blank" rel="noopener noreferrer">Kubernetes 问题排查：Pod 状态一直 Terminating</a></li>
<li>创建了 Deployment 后，却没有自动创建 Pod: 缺少某些创建 Pod 必要的东西，比如设定的 ServiceAccount 不存在。</li>
<li>Pod 运行失败，状态为 MatchNodeSelector: 对主节点进行关机、迁移等操作，导致主调度器下线时，会在一段时间内导致 Pod 调度失败，调度失败会报这个错。</li>
<li>Pod 仍然存在，但是 <code>Service</code> 的 Endpoints 却为空，找不到对应的 Pod IPs: 遇到过一次，是因为时间跳变（从未来的时间改回了当前时间）导致的问题。</li>
</ol>
<h3 id="控制面故障可能会导致各类奇怪的异常现象">控制面故障可能会导致各类奇怪的异常现象</h3>
<p>对于生产环境的集群，因为有高可用，通常我们比较少遇到控制面故障问题。但是一旦控制面发生故障，就可能会导致各类奇怪的异常现象。
如果能在排查问题时，把控制面异常考虑进来，在这种情况下，就能节约大量的排查时间，快速定位到问题。</p>
<p>其中比较隐晦的就是 controller-manager 故障导致的异常：</p>
<ol>
<li>节点的服务器已经被终止，但是 Kuberntes 里还显示 node 为 Ready 状态，不会更新为 NotReady.</li>
<li>被删除的 Pods 可能会卡在 Terminating 状态，只有强制删除才能删除掉它们。并且确认 Pod 没有 <code>metadata.finalizers</code> 属性</li>
<li>HPA 的动态伸缩功能失效</li>
<li>&hellip;</li>
</ol>
<p>如果这些现象同时发生，就要怀疑是否是 kube-controller-manager 出问题了.</p>
<p>其他控制面异常的详细分析，参见 <a href="./kubernetes%20%e6%8e%a7%e5%88%b6%e9%9d%a2%e6%95%85%e9%9a%9c%e7%8e%b0%e8%b1%a1%e5%8f%8a%e5%88%86%e6%9e%90.md" rel="">kubernetes 控制面故障现象及分析</a></p>
<h3 id="pod-无法删除">Pod 无法删除</h3>
<p>可能是某些资源无法被GC，这会导致容器已经 Exited 了，但是 Pod 一直处于 Terminating 状态。</p>
<p>这个问题在网上能搜到很多案例,但大都只是提供了如下的强制清理命令，未分析具体原因：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell">kubectl delete pods &lt;pod&gt; --grace-period<span class="o">=</span><span class="m">0</span> --force
</code></pre></td></tr></table>
</div>
</div><p>最近找到几篇详细的原因分析文章，值得一看：</p>
<ul>
<li><a href="https://cloud.tencent.com/developer/article/1680612" target="_blank" rel="noopener noreferrer">腾讯云原生 -【Pod Terminating原因追踪系列】之 containerd 中被漏掉的 runc 错误信息</a></li>
<li><a href="https://cloud.tencent.com/developer/article/1680613" target="_blank" rel="noopener noreferrer">腾讯云原生 -【Pod Terminating原因追踪系列之二】exec连接未关闭导致的事件阻塞</a></li>
<li><a href="https://cloud.tencent.com/developer/article/1689486" target="_blank" rel="noopener noreferrer">腾讯云原生 -【Pod Terminating原因追踪系列之三】让docker事件处理罢工的cancel状态码</a></li>
<li><a href="https://www.likakuli.com/posts/docker-pod-terminating/" target="_blank" rel="noopener noreferrer">Pod terminating - 问题排查 - KaKu Li</a></li>
</ul>
<p>大致总结一下，主要原因来自 docker 18.06 以及 kubernetes 的 docker-shim 运行时的底层逻辑，已经在新版本被修复了。</p>
<h3 id="initcontainers-不断-restart但是-containers-却都显示已-ready">initContainers 不断 restart，但是 Containers 却都显示已 ready</h3>
<p>Kubernetes 应该确保所有 initContainers 都 Completed，然后才能启动 Containers.</p>
<p>但是我们发现有一个节点上，所有包含 initContainers 的 Pod，状态全都是 <code>Init:CrashLoopBackOff</code> 或者 <code>Init:Error</code>.</p>
<p>而且进一步 <code>kubectl describe po</code> 查看细节，发现 initContainer 的状态为:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-fallback" data-lang="fallback">...
    State:          Waiting
      Reason:       CrashLoopBackOff
    Last State:     Terminated
      Reason:       Error
      Exit Code:    2
      Started:      Tue, 03 Aug 2021 06:02:42 +0000
      Finished:     Tue, 03 Aug 2021 06:02:42 +0000
    Ready:          False
    Restart Count:  67
...
</code></pre></td></tr></table>
</div>
</div><p>而 Containers 的状态居然是 ready:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-fallback" data-lang="fallback">...
    Host Port:      0/TCP
    State:          Running
      Started:      Tue, 03 Aug 2021 00:35:30 +0000
    Ready:          True
    Restart Count:  0
...
</code></pre></td></tr></table>
</div>
</div><p>initContainers 还未运行成功，而 Containers 却 Ready 了，非常疑惑。</p>
<p>仔细想了下，早上因为磁盘余量告警，有手动运行过 <code>docker system prune</code> 命令，那么问题可能就是这条命令清理掉了已经 exited 的 initContainers 容器，导致 k8s 故障，不断尝试重启该容器。</p>
<p>网上一搜确实有相关的信息：</p>
<ul>
<li><a href="https://stackoverflow.com/questions/62333064/cant-delete-exited-init-container">https://stackoverflow.com/questions/62333064/cant-delete-exited-init-container</a></li>
<li><a href="https://github.com/kubernetes/kubernetes/issues/62362">https://github.com/kubernetes/kubernetes/issues/62362</a></li>
</ul>
<p>结论：使用外部的垃圾清理命令可能导致 k8s 行为异常。</p>
<h2 id="节点常见错误">节点常见错误</h2>
<ol>
<li><a href="https://kubernetes.io/docs/tasks/administer-cluster/out-of-resource/#node-conditions" target="_blank" rel="noopener noreferrer">DiskPressure</a>：节点的可用空间不足。（通过<code>df -h</code> 查看，保证可用空间不小于 15%）</li>
<li>The node was low on resource: ephemeral-storage: 同上，节点的存储空间不够了。</li>
</ol>
<p>节点存储告警可能的原因：</p>
<ol>
<li>kubelet 的资源 GC 设置有问题，遗留的镜像等资源未及时 GC 导致告警</li>
<li>存在运行的 pod 使用了大量存储空间，在节点上通过 <code>docker ps -a --size | grep G</code> 可以查看到</li>
<li>如果使用的是 EKS，并且磁盘告警的挂载点为 <code>/var/lib/kubelet/plugins/kubernetes.io/aws-ebs/mounts/aws/us-east-1b/vol-xxxxx</code>
<ol>
<li>显然是 EBS 存储卷快满了导致的</li>
<li>可通过 <code> kubectl get pv -A -o yaml | grep -C 30 vol-xxxxx</code> 来定位到具体的存储卷</li>
</ol>
</li>
</ol>
<h2 id="网络常见错误">网络常见错误</h2>
<h3 id="1-ingressistio-gateway-返回值">1. Ingress/Istio Gateway 返回值</h3>
<ol>
<li>404：不存在该 Service/Istio Gateway，或者是服务自身返回 404</li>
<li>500：大概率是服务自身的错误导致 500，小概率是代理（Sidecar/Ingress 等）的错误</li>
<li>503：服务不可用，有如下几种可能的原因：
<ol>
<li>Service 对应的 Pods 不存在，endpoints 为空</li>
<li>Service 对应的 Pods 全部都 NotReady，导致 endpoints 为空</li>
<li>也有可能是服务自身出错返回的 503</li>
<li>如果你使用了 envoy sidecar， 503 可能的原因就多了。基本上 sidecar 与主容器通信过程中的任何问题都会使 envoy 返回 503，使客户端重试。
<ol>
<li>详见 <a href="https://blog.fleeto.us/post/istio-503-uc-debug/" target="_blank" rel="noopener noreferrer">Istio：503、UC 和 TCP</a></li>
</ol>
</li>
</ol>
</li>
<li>502：Bad Gateway，通常是由于上游未返回正确的响应导致的，可能的根本原因：
<ol>
<li>应用程序未正确处理 SIGTERM 信号，在请求未处理完毕时直接终止了进程。详见 <a href="./%e6%9c%80%e4%bd%b3%e5%ae%9e%e8%b7%b5.md" rel="">优雅停止（Gracful Shutdown）与 502/504 报错 - K8s 最佳实践</a></li>
<li>网络插件 bug</li>
</ol>
</li>
<li>504：网关请求 upstream 超时，主要有两种可能
<ol>
<li>考虑是不是 Ingress Controller 的 IP 列表未更新，将请求代理到了不存在的 ip，导致得不到响应</li>
<li>Service Endpoints 移除不够及时，在 Pod 已经被终止后，仍然有个别请求被路由到了该 Pod，得不到响应导致 504。详见 <a href="./%e6%9c%80%e4%bd%b3%e5%ae%9e%e8%b7%b5.md" rel="">优雅停止（Gracful Shutdown）与 502/504 报错 - K8s 最佳实践</a></li>
<li>Pod 响应太慢，代码问题</li>
</ol>
</li>
</ol>
<p>再总结一下常见的几种错误：</p>
<ul>
<li>未设置优雅停止，导致 Pod 被重新终止时，有概率出现 502/504</li>
<li>服务的所有 Pods 的状态在「就绪」和「未就绪」之间摆动，导致间歇性地出现大量 503 错误</li>
<li>服务返回 5xx 错误导致客户端不断重试，请求流量被放大，导致服务一直起不来
<ul>
<li>解决办法：限流、熔断（网关层直接返回固定的相应内容）</li>
</ul>
</li>
</ul>
<p>Ingress 相关网络问题的排查流程：</p>
<ol>
<li>Which ingress controller?</li>
<li>Timeout between client and ingress controller, or between ingress controller and backend service/pod?</li>
<li>HTTP/504 generated by the ingress controller, proven by logs from the ingress controller?</li>
<li>If you port-forward to skip the internet between client and ingress controller, does the timeout still happen?</li>
</ol>
<h3 id="2-上了-istio-sidecar-后应用程序偶尔间隔几天半个月会-redis-连接相关的错误">2. 上了 istio sidecar 后，应用程序偶尔（间隔几天半个月）会 redis 连接相关的错误</h3>
<p>考虑是否和 tcp 长时间使用有关，比如连接长时间空闲的话，可能会被 istio sidecar 断开。
如果程序自身的重连机制有问题，就会导致这种现象。</p>
<p>确认方法：</p>
<ol>
<li>检查 istio 的 <code>idleTimeout</code> 时长（默认 1h）</li>
<li>创建三五个没流量的 Pod 放置 1h（与 istio idleTimeout 时长一致），看看是否会准时开始报 redis 的错。</li>
<li>对照组：创建三五个同样没流量的 Pod，但是不注入 istio sidecar，应该一直很正常</li>
</ol>
<p>这样就能确认问题，后续处理：</p>
<ol>
<li>抓包观察程序在出错后的 tcp 层行为</li>
<li>查阅 redis sdk 的相关 issue、代码，通过升级 SDK 应该能解决问题。</li>
</ol>
<h2 id="名字空间常见错误">名字空间常见错误</h2>
<h3 id="名字空间无法删除">名字空间无法删除</h3>
<p>这通常是某些资源如 CR(custom resources)/存储等资源无法释放导致的。
比如常见的 monitoring 名字空间无法删除，应该就是 CR 无法 GC 导致的。</p>
<p>可手动删除 namespace 配置中的析构器（spec.finalizer，在名字空间生命周期结束前会生成的配置项），这样名字空间就会直接跳过 GC 步骤：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell"><span class="c1"># 编辑名字空间的配置</span>
kubectl edit namespace &lt;ns-name&gt;
<span class="c1"># 将 spec.finalizers 改成空列表 []</span>
</code></pre></td></tr></table>
</div>
</div><p>如果上述方法也无法删除名字空间，也找不到具体的问题，就只能直接从 etcd 中删除掉它了(有风险，谨慎操作！)。方法如下：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span><span class="lnt">8
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell"><span class="c1"># 登录到 etcd 容器中，执行如下命令：</span>
<span class="nb">export</span> <span class="nv">ETCDCTL_API</span><span class="o">=</span><span class="m">3</span>
<span class="nb">cd</span> /etc/kubernetes/pki/etcd/
<span class="c1"># 列出所有名字空间</span>
etcdctl --cacert ca.crt --cert peer.crt --key peer.key get /registry/namespaces --prefix --keys-only

<span class="c1"># （谨慎操作！！！）强制删除名字空间 `monitoring`。这可能导致相关资源无法被 GC！</span>
etcdctl --cacert ca.crt --cert peer.crt --key peer.key del /registry/namespaces/monitoring
</code></pre></td></tr></table>
</div>
</div><h2 id="kubectlistioctl-等客户端工具异常">kubectl/istioctl 等客户端工具异常</h2>
<ol>
<li><code>socat not found</code>: kubectl 使用 <code>socat</code> 进行端口转发，集群的所有节点，以及本机都必须安装有 <code>socat</code> 工具。</li>
</ol>
<h2 id="批量清理-evicted-记录">批量清理 Evicted 记录</h2>
<p>有时候 Pod 因为节点选择器的问题，被不断调度到有问题的 Node 上，就会不断被 Evicted，导致出现大量的 Evicted Pods。
排查完问题后，需要手动清理掉这些 Evicted Pods.</p>
<p>批量删除 Evicted 记录:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell">kubectl get pods <span class="p">|</span> grep Evicted <span class="p">|</span> awk <span class="s1">&#39;{print $1}&#39;</span> <span class="p">|</span> xargs kubectl delete pod
</code></pre></td></tr></table>
</div>
</div><h2 id="容器镜像gcpod驱逐以及节点压力">容器镜像GC、Pod驱逐以及节点压力</h2>
<p>节点压力 DiskPressure 会导致 Pod 被驱逐，也会触发容器镜像的 GC。</p>
<p>根据官方文档 <a href="https://kubernetes.io/zh/docs/tasks/administer-cluster/out-of-resource" target="_blank" rel="noopener noreferrer">配置资源不足时的处理方式</a>，Kubelet 提供如下用于配置容器 GC 及 Evicetion 的阈值：</p>
<ol>
<li><code>--eviction-hard</code> 和 <code>eviction-soft</code>: 对应旧参数 <code>--image-gc-high-threshold</code>，这两个参数配置镜像 GC 及驱逐的触发阈值。磁盘使用率的阈值默认为 85%
<ol>
<li>区别在于 <code>eviction-hard</code> 是立即驱逐，而 <code>eviction-soft</code> 在超过 <code>eviction-soft-grace-period</code> 之后才驱逐。</li>
</ol>
</li>
<li><code>--eviction-minimum-reclaim</code>: 对应旧参数 <code>--image-gc-low-threshold</code>。这是进行资源回收（镜像GC、Pod驱逐等）后期望达到的磁盘使用率百分比。磁盘使用率的阈值默认值为 80%。</li>
</ol>
<p>问：能否为 ImageGC 设置一个比 DiskPressure 更低的阈值？因为我们希望能自动进行镜像 GC，但是不想立即触发 Pod 驱逐。</p>
<p>答：这应该可以通过设置 <code>eviction-soft</code> 和长一点的 <code>eviction-soft-grace-period</code> 来实现。
另外 <code>--eviction-minimum-reclaim</code> 也可以设小一点，清理得更干净。示例如下：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell">--eviction-soft<span class="o">=</span>memory.available&lt;1Gi,nodefs.available&lt;2Gi,imagefs.available&lt;200Gi
--eviction-soft-grace-period<span class="o">=</span>3m
--eviction-minimum-reclaim<span class="o">=</span>memory.available<span class="o">=</span>0Mi,nodefs.available<span class="o">=</span>1Gi,imagefs.available<span class="o">=</span>2Gi
</code></pre></td></tr></table>
</div>
</div><h2 id="其他问题">其他问题</h2>
<h2 id="隔天-istio-等工具的-sidecar-自动注入莫名其妙失效了">隔天 Istio 等工具的 sidecar 自动注入莫名其妙失效了</h2>
<p>如果服务器晚上会关机，可能导致第二天网络插件出问题，导致 sidecar 注入器无法观察到 pod 的创建，也就无法完成 sidecar 注入。</p>
<h3 id="如何重新运行一个-job">如何重新运行一个 Job？</h3>
<p>我们有一个 Job 因为外部原因运行失败了，修复好后就需要重新运行它。</p>
<p>方法是：删除旧的 Job，再使用同一份配置重建 Job.</p>
<p>如果你使用的是 fluxcd 这类 GitOps 工具，就只需要手工删除旧 Pod，fluxcd 会定时自动 apply 所有配置，这就完成了 Job 的重建。</p>
<h2 id="参考">参考</h2>
<ul>
<li><a href="https://yq.aliyun.com/articles/703971?type=2" target="_blank" rel="noopener noreferrer">Kubernetes管理经验</a></li>
<li><a href="https://www.reddit.com/r/kubernetes/comments/ced0py/504_gateway_timeout_when_accessing_workload_via/" target="_blank" rel="noopener noreferrer">504 Gateway Timeout when accessing workload via ingress</a></li>
<li><a href="https://k8s.af/" target="_blank" rel="noopener noreferrer">Kubernetes Failure Stories</a></li>
<li><a href="https://blog.fleeto.us/post/istio-503-uc-debug/" target="_blank" rel="noopener noreferrer">Istio：503、UC 和 TCP</a></li>
</ul>
]]></description></item></channel></rss>